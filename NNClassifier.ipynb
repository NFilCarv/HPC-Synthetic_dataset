{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "824c29c9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           inst      bi   time  label\n",
      "0        274560   29756    427      1\n",
      "1        273975   29862    389      1\n",
      "2        273510   29309    389      1\n",
      "3        274614   29368    417      1\n",
      "4        273029   29531    428      1\n",
      "...         ...     ...    ...    ...\n",
      "199995   827159  314966    336      0\n",
      "199996     1916    1831  10270      0\n",
      "199997   132652     125   1797      0\n",
      "199998  4743522     575   4179      0\n",
      "199999   277053     362    679      0\n",
      "\n",
      "[200000 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet('dataset.parquet', engine='pyarrow')\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d641a64",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from keras.callbacks import EarlyStopping\n",
    "import joblib\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_parquet('dataset.parquet', engine='pyarrow')\n",
    "\n",
    "# Split the dataset into features and labels\n",
    "X = df[['inst', 'bi', 'time']]\n",
    "y = df['label']\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define a function to create the model\n",
    "def create_model(activation1,activation2,activation3,activation4,activation5, optimizer, dropout):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(3,)))\n",
    "    model.add(Dense(units=256, activation=activation1, kernel_initializer='glorot_uniform'))\n",
    "    model.add(Dropout(rate=dropout))\n",
    "    model.add(Dense(units=128, activation=activation2))\n",
    "    model.add(Dropout(rate=dropout))\n",
    "    model.add(Dense(units=64, activation=activation3))\n",
    "    model.add(Dropout(rate=dropout))\n",
    "    model.add(Dense(units=32, activation=activation4))\n",
    "    model.add(Dropout(rate=dropout))\n",
    "    model.add(Dense(units=16, activation=activation5))\n",
    "    model.add(Dropout(rate=dropout))\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'batch_size': [100, 1024],\n",
    "    'epochs': [100],\n",
    "    'model__activation1': ['relu', 'tanh'],\n",
    "    'model__activation2': ['relu', 'tanh'],\n",
    "    'model__activation3': ['relu', 'tanh'],\n",
    "    'model__activation4': ['relu', 'tanh'],\n",
    "    'model__activation5': ['relu', 'tanh'],\n",
    "    'model__optimizer': ['adam', 'rmsprop'],\n",
    "    'model__dropout': [0.25,0.5]\n",
    "}\n",
    "\n",
    "# Wrap the Keras model with the KerasClassifier\n",
    "model = KerasClassifier(\n",
    "    model=create_model,\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)],\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Perform grid search\n",
    "gs = GridSearchCV(estimator=model, param_grid=param_grid, scoring='accuracy', cv=10, n_jobs=-1, return_train_score=True, verbose=0)\n",
    "gs_result = gs.fit(X_train_scaled, y_train, validation_data=(X_valid_scaled, y_valid))\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(f\"Best Parameters: {gs_result.best_params_}\")\n",
    "print(f\"Best Score: {gs_result.best_score_}\")\n",
    "\n",
    "best_model = gs_result.best_estimator_\n",
    "accuracy = best_model.score(X_test_scaled, y_test)\n",
    "print(f'Test Accuracy: {accuracy:.4f}')\n",
    "\n",
    "best_model.model_.save('nn_model.keras')\n",
    "joblib.dump(scaler, 'scaler.joblib')\n",
    "\n",
    "y_pred_prob = best_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49748d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d65b403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Nuno\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Nuno\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Nuno\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:From C:\\Users\\Nuno\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Nuno\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "5860/5860 [==============================] - 17s 3ms/step - loss: 0.3142 - accuracy: 0.8571 - val_loss: 0.1936 - val_accuracy: 0.9232\n",
      "Epoch 2/50\n",
      "5860/5860 [==============================] - 15s 3ms/step - loss: 0.1746 - accuracy: 0.9356 - val_loss: 0.1683 - val_accuracy: 0.9336\n",
      "Epoch 3/50\n",
      "5860/5860 [==============================] - 15s 3ms/step - loss: 0.1577 - accuracy: 0.9415 - val_loss: 0.1512 - val_accuracy: 0.9484\n",
      "Epoch 4/50\n",
      "5860/5860 [==============================] - 15s 3ms/step - loss: 0.1537 - accuracy: 0.9427 - val_loss: 0.1559 - val_accuracy: 0.9424\n",
      "Epoch 5/50\n",
      "5860/5860 [==============================] - 15s 3ms/step - loss: 0.1515 - accuracy: 0.9428 - val_loss: 0.1417 - val_accuracy: 0.9426\n",
      "Epoch 6/50\n",
      "5860/5860 [==============================] - 15s 3ms/step - loss: 0.1492 - accuracy: 0.9441 - val_loss: 0.1560 - val_accuracy: 0.9436\n",
      "Epoch 7/50\n",
      "5860/5860 [==============================] - 15s 3ms/step - loss: 0.1490 - accuracy: 0.9438 - val_loss: 0.1387 - val_accuracy: 0.9481\n",
      "Epoch 8/50\n",
      "5860/5860 [==============================] - 15s 3ms/step - loss: 0.1477 - accuracy: 0.9441 - val_loss: 0.1372 - val_accuracy: 0.9526\n",
      "Epoch 9/50\n",
      "5860/5860 [==============================] - 15s 3ms/step - loss: 0.1461 - accuracy: 0.9446 - val_loss: 0.1401 - val_accuracy: 0.9551\n",
      "Epoch 10/50\n",
      "5860/5860 [==============================] - 15s 3ms/step - loss: 0.1458 - accuracy: 0.9455 - val_loss: 0.1381 - val_accuracy: 0.9536\n",
      "Epoch 11/50\n",
      "5860/5860 [==============================] - 15s 3ms/step - loss: 0.1447 - accuracy: 0.9457 - val_loss: 0.1359 - val_accuracy: 0.9517\n",
      "Epoch 12/50\n",
      "5860/5860 [==============================] - 15s 3ms/step - loss: 0.1436 - accuracy: 0.9457 - val_loss: 0.1434 - val_accuracy: 0.9446\n",
      "Epoch 13/50\n",
      "5860/5860 [==============================] - 15s 3ms/step - loss: 0.1431 - accuracy: 0.9457 - val_loss: 0.1426 - val_accuracy: 0.9472\n",
      "Epoch 14/50\n",
      "5860/5860 [==============================] - 15s 3ms/step - loss: 0.1426 - accuracy: 0.9458 - val_loss: 0.1358 - val_accuracy: 0.9485\n",
      "Epoch 15/50\n",
      "5860/5860 [==============================] - 15s 3ms/step - loss: 0.1434 - accuracy: 0.9455 - val_loss: 0.1405 - val_accuracy: 0.9450\n",
      "Epoch 16/50\n",
      "5860/5860 [==============================] - 15s 3ms/step - loss: 0.1416 - accuracy: 0.9459 - val_loss: 0.1366 - val_accuracy: 0.9501\n",
      "Epoch 17/50\n",
      "5860/5860 [==============================] - 15s 3ms/step - loss: 0.1405 - accuracy: 0.9465 - val_loss: 0.1545 - val_accuracy: 0.9496\n",
      "Epoch 18/50\n",
      "5860/5860 [==============================] - 15s 3ms/step - loss: 0.1413 - accuracy: 0.9465 - val_loss: 0.1387 - val_accuracy: 0.9504\n",
      "Epoch 19/50\n",
      "5860/5860 [==============================] - 20s 3ms/step - loss: 0.1410 - accuracy: 0.9463 - val_loss: 0.1432 - val_accuracy: 0.9440\n",
      "Epoch 20/50\n",
      "5860/5860 [==============================] - 19s 3ms/step - loss: 0.1393 - accuracy: 0.9473 - val_loss: 0.1444 - val_accuracy: 0.9491\n",
      "Epoch 21/50\n",
      "5860/5860 [==============================] - 20s 3ms/step - loss: 0.1395 - accuracy: 0.9471 - val_loss: 0.1368 - val_accuracy: 0.9468\n",
      "Epoch 22/50\n",
      "5860/5860 [==============================] - 20s 3ms/step - loss: 0.1380 - accuracy: 0.9479 - val_loss: 0.1357 - val_accuracy: 0.9492\n",
      "Epoch 23/50\n",
      "5860/5860 [==============================] - 19s 3ms/step - loss: 0.1378 - accuracy: 0.9476 - val_loss: 0.1288 - val_accuracy: 0.9527\n",
      "Epoch 24/50\n",
      "5860/5860 [==============================] - 19s 3ms/step - loss: 0.1382 - accuracy: 0.9476 - val_loss: 0.1578 - val_accuracy: 0.9339\n",
      "Epoch 25/50\n",
      "5860/5860 [==============================] - 19s 3ms/step - loss: 0.1392 - accuracy: 0.9477 - val_loss: 0.1411 - val_accuracy: 0.9451\n",
      "Epoch 26/50\n",
      "5860/5860 [==============================] - 19s 3ms/step - loss: 0.1368 - accuracy: 0.9485 - val_loss: 0.1521 - val_accuracy: 0.9452\n",
      "Epoch 27/50\n",
      "5860/5860 [==============================] - 19s 3ms/step - loss: 0.1358 - accuracy: 0.9491 - val_loss: 0.1247 - val_accuracy: 0.9558\n",
      "Epoch 28/50\n",
      "5860/5860 [==============================] - 20s 3ms/step - loss: 0.1361 - accuracy: 0.9488 - val_loss: 0.1256 - val_accuracy: 0.9551\n",
      "Epoch 29/50\n",
      "5860/5860 [==============================] - 19s 3ms/step - loss: 0.1345 - accuracy: 0.9498 - val_loss: 0.1396 - val_accuracy: 0.9465\n",
      "Epoch 30/50\n",
      "5860/5860 [==============================] - 20s 3ms/step - loss: 0.1339 - accuracy: 0.9500 - val_loss: 0.1352 - val_accuracy: 0.9541\n",
      "Epoch 31/50\n",
      "5860/5860 [==============================] - 19s 3ms/step - loss: 0.1348 - accuracy: 0.9498 - val_loss: 0.1266 - val_accuracy: 0.9537\n",
      "Epoch 32/50\n",
      "5860/5860 [==============================] - 19s 3ms/step - loss: 0.1332 - accuracy: 0.9503 - val_loss: 0.1350 - val_accuracy: 0.9495\n",
      "Epoch 33/50\n",
      "5860/5860 [==============================] - 21s 4ms/step - loss: 0.1329 - accuracy: 0.9505 - val_loss: 0.1464 - val_accuracy: 0.9452\n",
      "Epoch 34/50\n",
      "5860/5860 [==============================] - 20s 3ms/step - loss: 0.1338 - accuracy: 0.9505 - val_loss: 0.1629 - val_accuracy: 0.9394\n",
      "Epoch 35/50\n",
      "5860/5860 [==============================] - 21s 3ms/step - loss: 0.1336 - accuracy: 0.9506 - val_loss: 0.1193 - val_accuracy: 0.9593\n",
      "Epoch 36/50\n",
      "5860/5860 [==============================] - 20s 3ms/step - loss: 0.1312 - accuracy: 0.9511 - val_loss: 0.1281 - val_accuracy: 0.9533\n",
      "Epoch 37/50\n",
      "5860/5860 [==============================] - 21s 4ms/step - loss: 0.1324 - accuracy: 0.9508 - val_loss: 0.1454 - val_accuracy: 0.9381\n",
      "Epoch 38/50\n",
      "5860/5860 [==============================] - 20s 3ms/step - loss: 0.1318 - accuracy: 0.9508 - val_loss: 0.1376 - val_accuracy: 0.9488\n",
      "Epoch 39/50\n",
      "5860/5860 [==============================] - 20s 3ms/step - loss: 0.1322 - accuracy: 0.9510 - val_loss: 0.1207 - val_accuracy: 0.9538\n",
      "Epoch 40/50\n",
      "5860/5860 [==============================] - 20s 3ms/step - loss: 0.1311 - accuracy: 0.9516 - val_loss: 0.1188 - val_accuracy: 0.9554\n",
      "Epoch 41/50\n",
      "5860/5860 [==============================] - 19s 3ms/step - loss: 0.1313 - accuracy: 0.9511 - val_loss: 0.1195 - val_accuracy: 0.9574\n",
      "Epoch 42/50\n",
      "5860/5860 [==============================] - 33s 6ms/step - loss: 0.1315 - accuracy: 0.9511 - val_loss: 0.1318 - val_accuracy: 0.9494\n",
      "Epoch 43/50\n",
      "5860/5860 [==============================] - 22s 4ms/step - loss: 0.1291 - accuracy: 0.9525 - val_loss: 0.1312 - val_accuracy: 0.9494\n",
      "Epoch 44/50\n",
      "5860/5860 [==============================] - 21s 4ms/step - loss: 0.1304 - accuracy: 0.9516 - val_loss: 0.1198 - val_accuracy: 0.9548\n",
      "Epoch 45/50\n",
      "5860/5860 [==============================] - 19s 3ms/step - loss: 0.1305 - accuracy: 0.9519 - val_loss: 0.1338 - val_accuracy: 0.9452\n",
      "Epoch 46/50\n",
      "5860/5860 [==============================] - 14s 2ms/step - loss: 0.1277 - accuracy: 0.9530 - val_loss: 0.1324 - val_accuracy: 0.9502\n",
      "Epoch 47/50\n",
      "5860/5860 [==============================] - 20s 3ms/step - loss: 0.1278 - accuracy: 0.9530 - val_loss: 0.1190 - val_accuracy: 0.9581\n",
      "Epoch 48/50\n",
      "5860/5860 [==============================] - 23s 4ms/step - loss: 0.1287 - accuracy: 0.9527 - val_loss: 0.1216 - val_accuracy: 0.9562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50\n",
      "5860/5860 [==============================] - 22s 4ms/step - loss: 0.1280 - accuracy: 0.9528 - val_loss: 0.1174 - val_accuracy: 0.9572\n",
      "Epoch 50/50\n",
      "5860/5860 [==============================] - 25s 4ms/step - loss: 0.1270 - accuracy: 0.9536 - val_loss: 0.1295 - val_accuracy: 0.9528\n",
      "1954/1954 [==============================] - 5s 2ms/step - loss: 0.1278 - accuracy: 0.9543\n",
      "Test Accuracy: 0.9543\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_parquet('dataset.parquet', engine='pyarrow')\n",
    "\n",
    "X = df[['inst', 'bi', 'time']]\n",
    "y = df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.25, random_state=42)  \n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_shape=(3,), activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_data=(X_valid_scaled, y_valid))\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(f'Test Accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "421a488d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m5860/5860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - accuracy: 0.7155 - loss: 0.5548 - val_accuracy: 0.8711 - val_loss: 0.3082\n",
      "Epoch 2/50\n",
      "\u001b[1m5860/5860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.8724 - loss: 0.3215 - val_accuracy: 0.8832 - val_loss: 0.2721\n",
      "Epoch 3/50\n",
      "\u001b[1m5860/5860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.8854 - loss: 0.2949 - val_accuracy: 0.9071 - val_loss: 0.2234\n",
      "Epoch 4/50\n",
      "\u001b[1m5860/5860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.8910 - loss: 0.2828 - val_accuracy: 0.9074 - val_loss: 0.2234\n",
      "Epoch 5/50\n",
      "\u001b[1m5860/5860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.8956 - loss: 0.2732 - val_accuracy: 0.9079 - val_loss: 0.2188\n",
      "Epoch 6/50\n",
      "\u001b[1m5860/5860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.8977 - loss: 0.2677 - val_accuracy: 0.9195 - val_loss: 0.1982\n",
      "Epoch 7/50\n",
      "\u001b[1m5860/5860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.8999 - loss: 0.2642 - val_accuracy: 0.9167 - val_loss: 0.2038\n",
      "Epoch 8/50\n",
      "\u001b[1m5860/5860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.9013 - loss: 0.2591 - val_accuracy: 0.9163 - val_loss: 0.2056\n",
      "Epoch 9/50\n",
      "\u001b[1m5860/5860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.9015 - loss: 0.2600 - val_accuracy: 0.9240 - val_loss: 0.1901\n",
      "Epoch 10/50\n",
      "\u001b[1m5860/5860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.9032 - loss: 0.2562 - val_accuracy: 0.9169 - val_loss: 0.2012\n",
      "Epoch 11/50\n",
      "\u001b[1m5860/5860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.9044 - loss: 0.2530 - val_accuracy: 0.9249 - val_loss: 0.1882\n",
      "Epoch 12/50\n",
      "\u001b[1m5860/5860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.9061 - loss: 0.2487 - val_accuracy: 0.9230 - val_loss: 0.1956\n",
      "Epoch 13/50\n",
      "\u001b[1m5860/5860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.9066 - loss: 0.2491 - val_accuracy: 0.9258 - val_loss: 0.1862\n",
      "Epoch 14/50\n",
      "\u001b[1m5860/5860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.9055 - loss: 0.2498 - val_accuracy: 0.9146 - val_loss: 0.2102\n",
      "Epoch 15/50\n",
      "\u001b[1m5860/5860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9090 - loss: 0.2444 - val_accuracy: 0.9241 - val_loss: 0.1883\n",
      "Epoch 16/50\n",
      "\u001b[1m5860/5860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9090 - loss: 0.2427 - val_accuracy: 0.9272 - val_loss: 0.1779\n",
      "Epoch 17/50\n",
      "\u001b[1m5860/5860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.9089 - loss: 0.2429 - val_accuracy: 0.9241 - val_loss: 0.1845\n",
      "Epoch 18/50\n",
      "\u001b[1m5860/5860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.9074 - loss: 0.2456 - val_accuracy: 0.9259 - val_loss: 0.1870\n",
      "Epoch 19/50\n",
      "\u001b[1m5860/5860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.9097 - loss: 0.2400 - val_accuracy: 0.9291 - val_loss: 0.1783\n",
      "Epoch 20/50\n",
      "\u001b[1m5860/5860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.9080 - loss: 0.2436 - val_accuracy: 0.9291 - val_loss: 0.1772\n",
      "Epoch 21/50\n",
      "\u001b[1m5860/5860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.9079 - loss: 0.2426 - val_accuracy: 0.9295 - val_loss: 0.1791\n",
      "Epoch 22/50\n",
      "\u001b[1m5860/5860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - accuracy: 0.9122 - loss: 0.2368 - val_accuracy: 0.9277 - val_loss: 0.1812\n",
      "Epoch 23/50\n",
      "\u001b[1m5860/5860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - accuracy: 0.9116 - loss: 0.2379 - val_accuracy: 0.9294 - val_loss: 0.1735\n",
      "Epoch 24/50\n",
      "\u001b[1m5860/5860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - accuracy: 0.9103 - loss: 0.2390 - val_accuracy: 0.9300 - val_loss: 0.1761\n",
      "Epoch 25/50\n",
      "\u001b[1m5860/5860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - accuracy: 0.9128 - loss: 0.2357 - val_accuracy: 0.9267 - val_loss: 0.1810\n",
      "Epoch 26/50\n",
      "\u001b[1m5860/5860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - accuracy: 0.9111 - loss: 0.2375 - val_accuracy: 0.9335 - val_loss: 0.1709\n",
      "Epoch 27/50\n",
      "\u001b[1m5860/5860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - accuracy: 0.9117 - loss: 0.2376 - val_accuracy: 0.9275 - val_loss: 0.1800\n",
      "Epoch 28/50\n",
      "\u001b[1m5860/5860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - accuracy: 0.9123 - loss: 0.2368 - val_accuracy: 0.9296 - val_loss: 0.1774\n",
      "Epoch 29/50\n",
      "\u001b[1m5860/5860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - accuracy: 0.9127 - loss: 0.2368 - val_accuracy: 0.9270 - val_loss: 0.1833\n",
      "Epoch 30/50\n",
      "\u001b[1m5860/5860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - accuracy: 0.9102 - loss: 0.2386 - val_accuracy: 0.9304 - val_loss: 0.1744\n",
      "Epoch 31/50\n",
      "\u001b[1m5860/5860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - accuracy: 0.9119 - loss: 0.2356 - val_accuracy: 0.9301 - val_loss: 0.1749\n",
      "Epoch 32/50\n",
      "\u001b[1m5860/5860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - accuracy: 0.9119 - loss: 0.2382 - val_accuracy: 0.9312 - val_loss: 0.1736\n",
      "Epoch 33/50\n",
      "\u001b[1m5860/5860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - accuracy: 0.9125 - loss: 0.2341 - val_accuracy: 0.9300 - val_loss: 0.1750\n",
      "Epoch 34/50\n",
      "\u001b[1m5860/5860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - accuracy: 0.9134 - loss: 0.2317 - val_accuracy: 0.9307 - val_loss: 0.1783\n",
      "Epoch 35/50\n",
      "\u001b[1m5860/5860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - accuracy: 0.9119 - loss: 0.2353 - val_accuracy: 0.9281 - val_loss: 0.1779\n",
      "Epoch 36/50\n",
      "\u001b[1m5860/5860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - accuracy: 0.9113 - loss: 0.2380 - val_accuracy: 0.9249 - val_loss: 0.1895\n",
      "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9350 - loss: 0.1710\n",
      "Test Accuracy: 0.9354\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['scaler.joblib']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, LeakyReLU\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "import joblib\n",
    "\n",
    "df = pd.read_parquet('dataset.parquet', engine='pyarrow')\n",
    "\n",
    "X = df[['inst', 'bi', 'time']]\n",
    "y = df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.25, random_state=42)  # 0.25 * 0.8 = 0.2\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(3,)))\n",
    "\n",
    "model.add(Dense(64, activation='tanh'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(32, activation='tanh'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(16, activation='tanh'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_data=(X_valid_scaled, y_valid), callbacks=[early_stopping])\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "\n",
    "print(f'Test Accuracy: {accuracy:.4f}')\n",
    "\n",
    "model.save('nn_model.keras')\n",
    "\n",
    "joblib.dump(scaler, 'scaler.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fc632b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step\n",
      "[[0]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [0]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "\n",
    "def nnclassifier(parquet_path):\n",
    "    model = load_model('nn_model.keras')\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    scaler = joblib.load('scaler.joblib')\n",
    "    \n",
    "    dataset = pd.read_parquet(parquet_path)\n",
    "    \n",
    "    X_new = dataset[['inst', 'bi', 'time']]\n",
    "    \n",
    "    new_data_scaled = scaler.transform(X_new)\n",
    "    \n",
    "    predictions = model.predict(new_data_scaled)\n",
    "    \n",
    "    prediction_classes = (predictions > 0.5).astype(\"int32\")\n",
    "    \n",
    "    return prediction_classes\n",
    "\n",
    "parquet_path = 'teste.parquet'\n",
    "predicted_classes = nnclassifier(parquet_path)\n",
    "\n",
    "print(predicted_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1f41c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        0\n",
      "1        1\n",
      "2        0\n",
      "3        0\n",
      "4        0\n",
      "        ..\n",
      "99995    1\n",
      "99996    0\n",
      "99997    0\n",
      "99998    0\n",
      "99999    1\n",
      "Name: label, Length: 100000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet('teste.parquet', engine='pyarrow')\n",
    "\n",
    "lab = df['label']\n",
    "\n",
    "print (lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68d10cc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.80411\n",
      "[ True  True  True ... False  True  True]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "true_values = lab.values\n",
    "\n",
    "predictions_flat = predicted_classes.flatten()\n",
    "\n",
    "comparison = predictions_flat == true_values\n",
    "\n",
    "acc = 0\n",
    "for i in (comparison):\n",
    "    if i:\n",
    "        acc = acc+1\n",
    "    \n",
    "accuracy = (acc / len(true_values))\n",
    "\n",
    "print (accuracy)\n",
    "\n",
    "print(comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "112a71f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m5860/5860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - accuracy: 0.8136 - loss: 0.4134 - val_accuracy: 0.9010 - val_loss: 0.2657\n",
      "Epoch 2/50\n",
      "\u001b[1m5860/5860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.8978 - loss: 0.2802 - val_accuracy: 0.9147 - val_loss: 0.2638\n",
      "Epoch 3/50\n",
      "\u001b[1m5860/5860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.8947 - loss: 0.2817 - val_accuracy: 0.9229 - val_loss: 0.2065\n",
      "Epoch 4/50\n",
      "\u001b[1m5860/5860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9042 - loss: 0.2645 - val_accuracy: 0.9191 - val_loss: 0.2206\n",
      "Epoch 5/50\n",
      "\u001b[1m5860/5860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9030 - loss: 0.2671 - val_accuracy: 0.9114 - val_loss: 0.2363\n",
      "Epoch 6/50\n",
      "\u001b[1m5860/5860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9053 - loss: 0.2615 - val_accuracy: 0.9096 - val_loss: 0.2366\n",
      "Epoch 7/50\n",
      "\u001b[1m5860/5860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9065 - loss: 0.2566 - val_accuracy: 0.9267 - val_loss: 0.2343\n",
      "Epoch 8/50\n",
      "\u001b[1m5860/5860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - accuracy: 0.9090 - loss: 0.2530 - val_accuracy: 0.9174 - val_loss: 0.2292\n",
      "Epoch 9/50\n",
      "\u001b[1m5860/5860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - accuracy: 0.9055 - loss: 0.2626 - val_accuracy: 0.9157 - val_loss: 0.2262\n",
      "Epoch 10/50\n",
      "\u001b[1m5860/5860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.9052 - loss: 0.2583 - val_accuracy: 0.9160 - val_loss: 0.2274\n",
      "Epoch 11/50\n",
      "\u001b[1m5860/5860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9055 - loss: 0.2576 - val_accuracy: 0.9237 - val_loss: 0.2264\n",
      "Epoch 12/50\n",
      "\u001b[1m5860/5860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9061 - loss: 0.2602 - val_accuracy: 0.9209 - val_loss: 0.2499\n",
      "Epoch 13/50\n",
      "\u001b[1m5860/5860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9070 - loss: 0.2593 - val_accuracy: 0.9125 - val_loss: 0.2470\n",
      "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9252 - loss: 0.2048\n",
      "Test Accuracy: 0.9258\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['scaler.joblib']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import RMSprop\n",
    "##from keras.optimizers import Adam\n",
    "import joblib\n",
    "\n",
    "df = pd.read_parquet('dataset.parquet', engine='pyarrow')\n",
    "\n",
    "X = df[['inst', 'bi', 'time']]\n",
    "y = df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.25, random_state=42)  \n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(3,)))\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "optimizer = RMSprop(learning_rate=0.001)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_data=(X_valid_scaled, y_valid), callbacks=[early_stopping])\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "\n",
    "print(f'Test Accuracy: {accuracy:.4f}')\n",
    "\n",
    "model.save('nn_model.keras')\n",
    "\n",
    "joblib.dump(scaler, 'scaler.joblib')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1ea36e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.6059 - loss: 0.7756 - val_accuracy: 0.5011 - val_loss: 1.7715\n",
      "Epoch 2/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.7496 - loss: 0.4988 - val_accuracy: 0.5011 - val_loss: 2.2177\n",
      "Epoch 3/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.8842 - loss: 0.3061 - val_accuracy: 0.5011 - val_loss: 2.8927\n",
      "Epoch 4/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9070 - loss: 0.2595 - val_accuracy: 0.5011 - val_loss: 3.1281\n",
      "Epoch 5/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.9146 - loss: 0.2432 - val_accuracy: 0.4157 - val_loss: 3.0925\n",
      "Epoch 6/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.9193 - loss: 0.2289 - val_accuracy: 0.4384 - val_loss: 2.4954\n",
      "Epoch 7/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9191 - loss: 0.2280 - val_accuracy: 0.6995 - val_loss: 0.6542\n",
      "Epoch 8/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9220 - loss: 0.2205 - val_accuracy: 0.5231 - val_loss: 2.0371\n",
      "Epoch 9/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9249 - loss: 0.2128 - val_accuracy: 0.4169 - val_loss: 2.6336\n",
      "Epoch 10/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9260 - loss: 0.2118 - val_accuracy: 0.5676 - val_loss: 1.9568\n",
      "Epoch 11/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9247 - loss: 0.2104 - val_accuracy: 0.8382 - val_loss: 0.4450\n",
      "Epoch 12/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9253 - loss: 0.2085 - val_accuracy: 0.9208 - val_loss: 0.2199\n",
      "Epoch 13/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9255 - loss: 0.2077 - val_accuracy: 0.7299 - val_loss: 0.7908\n",
      "Epoch 14/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9273 - loss: 0.2028 - val_accuracy: 0.8624 - val_loss: 0.4270\n",
      "Epoch 15/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9269 - loss: 0.2028 - val_accuracy: 0.8862 - val_loss: 0.2912\n",
      "Epoch 16/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9293 - loss: 0.1996 - val_accuracy: 0.6894 - val_loss: 1.3521\n",
      "Epoch 17/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9263 - loss: 0.2028 - val_accuracy: 0.7896 - val_loss: 0.8912\n",
      "Epoch 18/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.9305 - loss: 0.1934 - val_accuracy: 0.8691 - val_loss: 0.3605\n",
      "Epoch 19/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9295 - loss: 0.1936 - val_accuracy: 0.9321 - val_loss: 0.1833\n",
      "Epoch 20/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.9283 - loss: 0.1965 - val_accuracy: 0.7081 - val_loss: 1.1003\n",
      "Epoch 21/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9270 - loss: 0.1985 - val_accuracy: 0.9401 - val_loss: 0.1764\n",
      "Epoch 22/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.9311 - loss: 0.1891 - val_accuracy: 0.9340 - val_loss: 0.1766\n",
      "Epoch 23/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9326 - loss: 0.1871 - val_accuracy: 0.9390 - val_loss: 0.1803\n",
      "Epoch 24/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9324 - loss: 0.1850 - val_accuracy: 0.8990 - val_loss: 0.2757\n",
      "Epoch 25/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.9342 - loss: 0.1835 - val_accuracy: 0.7741 - val_loss: 0.5634\n",
      "Epoch 26/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9347 - loss: 0.1803 - val_accuracy: 0.8979 - val_loss: 0.2488\n",
      "Epoch 27/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9340 - loss: 0.1810 - val_accuracy: 0.8108 - val_loss: 0.6030\n",
      "Epoch 28/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9325 - loss: 0.1825 - val_accuracy: 0.8493 - val_loss: 0.5334\n",
      "Epoch 29/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9335 - loss: 0.1842 - val_accuracy: 0.8635 - val_loss: 0.3790\n",
      "Epoch 30/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.9350 - loss: 0.1784 - val_accuracy: 0.7894 - val_loss: 0.7530\n",
      "Epoch 31/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.9354 - loss: 0.1785 - val_accuracy: 0.7618 - val_loss: 0.9900\n",
      "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9408 - loss: 0.1782\n",
      "Test Accuracy: 0.9413\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['scaler.joblib']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, LeakyReLU\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "import joblib\n",
    "\n",
    "df = pd.read_parquet('dataset.parquet', engine='pyarrow')\n",
    "\n",
    "X = df[['inst', 'bi', 'time']]\n",
    "y = df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(3,)))\n",
    "\n",
    "model.add(Dense(256, activation='tanh'))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "model.add(Dense(128, activation='tanh'))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(64, activation='tanh'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(32, activation='tanh'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(16, activation='tanh'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "##reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)\n",
    "\n",
    "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=1024, validation_data=(X_valid_scaled, y_valid), callbacks=[early_stopping])\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "\n",
    "print(f'Test Accuracy: {accuracy:.4f}')\n",
    "\n",
    "model.save('nn_model.keras')\n",
    "\n",
    "joblib.dump(scaler, 'scaler.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "205b800c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.6102 - loss: 8.3690 - val_accuracy: 0.4989 - val_loss: 1.0554\n",
      "Epoch 2/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.8979 - loss: 0.4973 - val_accuracy: 0.5011 - val_loss: 0.8182\n",
      "Epoch 3/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.9109 - loss: 0.3037 - val_accuracy: 0.5011 - val_loss: 0.6990\n",
      "Epoch 4/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.9152 - loss: 0.2816 - val_accuracy: 0.7562 - val_loss: 0.4641\n",
      "Epoch 5/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.9179 - loss: 0.2732 - val_accuracy: 0.8926 - val_loss: 0.2653\n",
      "Epoch 6/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.9165 - loss: 0.2711 - val_accuracy: 0.4898 - val_loss: 3.2480\n",
      "Epoch 7/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.9198 - loss: 0.2652 - val_accuracy: 0.4771 - val_loss: 1.6769\n",
      "Epoch 8/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.9211 - loss: 0.2569 - val_accuracy: 0.5872 - val_loss: 2.3370\n",
      "Epoch 9/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.9213 - loss: 0.2559 - val_accuracy: 0.6092 - val_loss: 2.0839\n",
      "Epoch 10/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.9196 - loss: 0.2594 - val_accuracy: 0.4896 - val_loss: 1.4514\n",
      "Epoch 11/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.9204 - loss: 0.2553 - val_accuracy: 0.5406 - val_loss: 2.0610\n",
      "Epoch 12/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.9211 - loss: 0.2534 - val_accuracy: 0.4962 - val_loss: 5.0867\n",
      "Epoch 13/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.9238 - loss: 0.2481 - val_accuracy: 0.8327 - val_loss: 0.4128\n",
      "Epoch 14/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.9213 - loss: 0.2533 - val_accuracy: 0.5908 - val_loss: 1.4008\n",
      "Epoch 15/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.9213 - loss: 0.2500 - val_accuracy: 0.4998 - val_loss: 3.3828\n",
      "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8905 - loss: 0.2676\n",
      "Test Accuracy: 0.8908\n",
      "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkIAAAHHCAYAAABTMjf2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/av/WaAAAACXBIWXMAAA9hAAAPYQGoP6dpAACCWUlEQVR4nO3dd1hT1x8G8DeEvVFkiCjDvRX3wlWxtu4q1oVWrdvW0TrraB1V62ytq1XUah1VK3XRah1VqQP3gipScYCgyJKZnN8f/EhIASUI3EDez/PweHJy782bBMw35557r0wIIUBERESkhwykDkBEREQkFRZCREREpLdYCBEREZHeYiFEREREeouFEBEREektFkJERESkt1gIERERkd5iIURERER6i4UQERER6S0WQkSFxM3NDUOGDJE6ht5p27Yt2rZtK3WMN5o7dy5kMhliYmKkjqJzZDIZ5s6dWyjbCg8Ph0wmg7+/f6Fsj0o/FkJUIvj7+0Mmk6l+DA0N4eLigiFDhuDx48dSx9NpSUlJ+Oqrr1C3bl2Ym5vDxsYGrVu3xtatW1FSrrBz+/ZtzJ07F+Hh4VJHyUGhUGDz5s1o27YtypQpAxMTE7i5uWHo0KG4dOmS1PEKxY4dO7By5UqpY2jQxUxUMhlKHYBIG19++SXc3d2RkpKCv//+G/7+/jhz5gxu3rwJU1NTSbOFhITAwEC3vltERUWhQ4cOuHPnDvr164dx48YhJSUFe/fuhZ+fHw4fPozt27dDLpdLHfW1bt++jXnz5qFt27Zwc3PTuO/333+XJhSA5ORk9OrVC0ePHkWbNm0wY8YMlClTBuHh4di9eze2bNmChw8fokKFCpJlLAw7duzAzZs38emnnxbJ9pOTk2FoqN3HUV6ZKlWqhOTkZBgZGRViQirNWAhRifLuu++iUaNGAIDhw4fD3t4eixcvRkBAAPr27StpNhMTk2J/zJSUFBgbG+dZgPn5+eHOnTvYv38/unXrpuqfMGECPvvsM3zzzTdo0KABpk6dWlyRAWSOUllYWBTKtoyNjQtlOwXx2Wef4ejRo1ixYkWOD+Q5c+ZgxYoVxZpHCIGUlBSYmZkV6+MWhFKpRFpaGkxNTQv1S4xMJpP8SxGVMIKoBNi8ebMAIC5evKjRf/DgQQFALFy4UKP/zp07onfv3sLOzk6YmJgILy8vceDAgRzbjY2NFZ9++qmoVKmSMDY2Fi4uLmLQoEEiOjpatUxKSoqYPXu28PT0FMbGxqJChQris88+EykpKRrbqlSpkvDz8xNCCHHx4kUBQPj7++d4zKNHjwoA4rffflP1PXr0SAwdOlQ4ODgIY2NjUbNmTfHjjz9qrHfixAkBQPz8889i5syZonz58kImk4nY2NhcX7OgoCABQHz00Ue53p+eni6qVKki7OzsxKtXr4QQQjx48EAAEEuXLhXLly8XFStWFKampqJNmzbixo0bObaRn9c56707efKkGD16tChXrpywtbUVQggRHh4uRo8eLapWrSpMTU1FmTJlxAcffCAePHiQY/3//pw4cUIIIYS3t7fw9vbO8Trt2rVLzJ8/X7i4uAgTExPRvn178c8//+R4Dt99951wd3cXpqamonHjxuL06dM5tpmbiIgIYWhoKN55553XLpdlzpw5AoD4559/hJ+fn7CxsRHW1tZiyJAhIikpSWPZTZs2iXbt2oly5coJY2NjUaNGDfH999/n2GalSpXEe++9J44ePSq8vLyEiYmJWLFihVbbEEKIw4cPizZt2ghLS0thZWUlGjVqJLZv3y6EyHx9//vaV6pUSbVufv8+AIixY8eKn376SdSsWVMYGhqK/fv3q+6bM2eOatn4+HjxySefqP4uy5UrJzp27CiCg4PfmCnrd3jz5s0aj3/nzh3Rp08fYW9vL0xNTUXVqlXFjBkzXveWkZ7giBCVaFlzRuzs7FR9t27dQsuWLeHi4oJp06bBwsICu3fvRo8ePbB371707NkTAJCYmIjWrVvjzp07+Oijj9CwYUPExMQgICAAjx49gr29PZRKJbp164YzZ87g448/Ro0aNXDjxg2sWLECoaGh+PXXX3PN1ahRI3h4eGD37t3w8/PTuG/Xrl2ws7ODj48PgMzdV82aNYNMJsO4ceNQrlw5HDlyBMOGDUN8fHyOkYavvvoKxsbGmDJlClJTU/McEfntt98AAIMHD871fkNDQ/Tv3x/z5s3D2bNn0bFjR9V9W7duRUJCAsaOHYuUlBSsWrUK7du3x40bN+Do6KjV65xlzJgxKFeuHGbPno2kpCQAwMWLF3Hu3Dn069cPFSpUQHh4ONauXYu2bdvi9u3bMDc3R5s2bTBhwgSsXr0aM2bMQI0aNQBA9W9evv76axgYGGDKlCmIi4vDkiVLMGDAAJw/f161zNq1azFu3Di0bt0aEydORHh4OHr06AE7O7s37s46cuQIMjIyMGjQoNcu9199+/aFu7s7Fi1ahMuXL+OHH36Ag4MDFi9erJGrVq1a6NatGwwNDfHbb79hzJgxUCqVGDt2rMb2QkJC8OGHH2LkyJEYMWIEqlWrptU2/P398dFHH6FWrVqYPn06bG1tceXKFRw9ehT9+/fHzJkzERcXh0ePHqlGuCwtLQFA67+PP//8E7t378a4ceNgb2+fYzdnllGjRuGXX37BuHHjULNmTTx//hxnzpzBnTt30LBhw9dmys3169fRunVrGBkZ4eOPP4abmxvu37+P3377DQsWLMjfG0ell9SVGFF+ZI0KHDt2TERHR4uIiAjxyy+/iHLlygkTExMRERGhWrZDhw6iTp06Gt9IlUqlaNGihahSpYqqb/bs2QKA2LdvX47HUyqVQgghtm3bJgwMDMRff/2lcf+6desEAHH27FlVX/YRISGEmD59ujAyMhIvXrxQ9aWmpgpbW1uNUZphw4YJZ2dnERMTo/EY/fr1EzY2NqrRmqyRDg8PD1Xf6/To0UMAyHPESAgh9u3bJwCI1atXCyHU36bNzMzEo0ePVMudP39eABATJ05U9eX3dc5671q1aiUyMjI0Hj+355E1krV161ZV3549ezRGgbLLa0SoRo0aIjU1VdW/atUqAUA1spWamirKli0rGjduLNLT01XL+fv7CwBvHBGaOHGiACCuXLny2uWyZI0I/XeErmfPnqJs2bIafbm9Lj4+PsLDw0Ojr1KlSgKAOHr0aI7l87ONly9fCisrK9G0aVORnJyssWzW34AQQrz33nsao0BZtPn7ACAMDAzErVu3cmwH/xkRsrGxEWPHjs2xXHZ5ZcptRKhNmzbCyspK/Pvvv3k+R9JfujWzk+gNOnbsiHLlysHV1RUffPABLCwsEBAQoPr2/uLFC/z555/o27cvEhISEBMTg5iYGDx//hw+Pj74559/VEeZ7d27F/Xq1csxcgFkzjMAgD179qBGjRqoXr26alsxMTFo3749AODEiRN5ZvX19UV6ejr27dun6vv999/x8uVL+Pr6Asic07F371507doVQgiNx/Dx8UFcXBwuX76ssV0/P798zQFJSEgAAFhZWeW5TNZ98fHxGv09evSAi4uL6naTJk3QtGlTHD58GIB2r3OWESNG5JiUnf15pKen4/nz56hcuTJsbW1zPG9tDR06VGO0rHXr1gCAsLAwAMClS5fw/PlzjBgxQmOi7oABAzRGGPOS9Zq97vXNzahRozRut27dGs+fP9d4D7K/LnFxcYiJiYG3tzfCwsIQFxensb67u7tqdDG7/Gzjjz/+QEJCAqZNm5ZjXk3W38DraPv34e3tjZo1a75xu7a2tjh//jyePHnyxmXfJDo6GqdPn8ZHH32EihUratyXn+dIpR93jVGJsmbNGlStWhVxcXHYtGkTTp8+rTFJ+d69exBC4IsvvsAXX3yR6zaePXsGFxcX3L9/H717937t4/3zzz+4c+cOypUrl+e28lKvXj1Ur14du3btwrBhwwBk7hazt7dXfVBER0fj5cuX2LBhAzZs2JCvx3B3d39t5ixZH9AJCQmwtbXNdZm8iqUqVarkWLZq1arYvXs3AO1e59flTk5OxqJFi7B582Y8fvxY43D+/37ga+u/H3pZxU1sbCwA4N9//wUAVK5cWWM5Q0PDPHfZZGdtbQ1A/RoWRq6sbZ49exZz5sxBUFAQXr16pbF8XFwcbGxsVLfz+n3Izzbu378PAKhdu7ZWzyGLtn8f+f3dXbJkCfz8/ODq6govLy906dIFgwcPhoeHh9YZswrfgj5HKv1YCFGJ0qRJE9VRYz169ECrVq3Qv39/hISEwNLSEkqlEgAwZcqUXL8lAzk/+F5HqVSiTp06WL58ea73u7q6vnZ9X19fLFiwADExMbCyskJAQAA+/PBD1QhEVt6BAwfmmEuUpW7duhq383tEUI0aNfDrr7/i+vXraNOmTa7LXL9+HQDy9S09u4K8zrnlHj9+PDZv3oxPP/0UzZs3h42NDWQyGfr166d6jILK65QAopDOnVS9enUAwI0bN1C/fv18r/emXPfv30eHDh1QvXp1LF++HK6urjA2Nsbhw4exYsWKHK9Lbq+rttsoKG3/PvL7u9u3b1+0bt0a+/fvx++//46lS5di8eLF2LdvH9599923zk2UHQshKrHkcjkWLVqEdu3a4bvvvsO0adNU3xiNjIw0Jv/mxtPTEzdv3nzjMteuXUOHDh0KNIzu6+uLefPmYe/evXB0dER8fDz69eunur9cuXKwsrKCQqF4Y15tvf/++1i0aBG2bt2aayGkUCiwY8cO2NnZoWXLlhr3/fPPPzmWDw0NVY2UaPM6v84vv/wCPz8/LFu2TNWXkpKCly9faixXFLswKlWqBCBzdKtdu3aq/oyMDISHh+coQP/r3XffhVwux08//aT1hOnX+e2335CamoqAgACN0aPX7YYt6DY8PT0BADdv3nztF4S8Xv+3/ft4HWdnZ4wZMwZjxozBs2fP0LBhQyxYsEBVCOX38bJ+V9/0t076i3OEqERr27YtmjRpgpUrVyIlJQUODg5o27Yt1q9fj6dPn+ZYPjo6WtXu3bs3rl27hv379+dYLuvbed++ffH48WNs3LgxxzLJycmqo5/yUqNGDdSpUwe7du3Crl274OzsrFGUyOVy9O7dG3v37s31P+rsebXVokULdOzYEZs3b8bBgwdz3D9z5kyEhobi888/z/FN/ddff9WY43PhwgWcP39e9SGkzev8OnK5PMcIzbfffguFQqHRl3XOof8WSG+jUaNGKFu2LDZu3IiMjAxV//bt21W7z17H1dUVI0aMwO+//45vv/02x/1KpRLLli3Do0ePtMqVNWL0392EmzdvLvRtdOrUCVZWVli0aBFSUlI07su+roWFRa67Kt/27yM3CoUix2M5ODigfPnySE1NfWOm/ypXrhzatGmDTZs24eHDhxr3FdboIJVsHBGiEu+zzz5Dnz594O/vj1GjRmHNmjVo1aoV6tSpgxEjRsDDwwNRUVEICgrCo0ePcO3aNdV6v/zyC/r06YOPPvoIXl5eePHiBQICArBu3TrUq1cPgwYNwu7duzFq1CicOHECLVu2hEKhwN27d7F7924EBgaqdtXlxdfXF7Nnz4apqSmGDRuW4+SHX3/9NU6cOIGmTZtixIgRqFmzJl68eIHLly/j2LFjePHiRYFfm61bt6JDhw7o3r07+vfvj9atWyM1NRX79u3DyZMn4evri88++yzHepUrV0arVq0wevRopKamYuXKlShbtiw+//xz1TL5fZ1f5/3338e2bdtgY2ODmjVrIigoCMeOHUPZsmU1lqtfvz7kcjkWL16MuLg4mJiYoH379nBwcCjwa2NsbIy5c+di/PjxaN++Pfr27Yvw8HD4+/vD09MzXyMOy5Ytw/379zFhwgTs27cP77//Puzs7PDw4UPs2bMHd+/e1RgBzI9OnTrB2NgYXbt2xciRI5GYmIiNGzfCwcEh16LzbbZhbW2NFStWYPjw4WjcuDH69+8POzs7XLt2Da9evcKWLVsAAF5eXti1axcmTZqExo0bw9LSEl27di2Uv4//SkhIQIUKFfDBBx+gXr16sLS0xLFjx3Dx4kWNkcO8MuVm9erVaNWqFRo2bIiPP/4Y7u7uCA8Px6FDh3D16lWt8lEpJMmxakRayuuEikIIoVAohKenp/D09FQdnn3//n0xePBg4eTkJIyMjISLi4t4//33xS+//KKx7vPnz8W4ceOEi4uL6mRwfn5+Goeyp6WlicWLF4tatWoJExMTYWdnJ7y8vMS8efNEXFycarn/Hj6f5Z9//lGd9O3MmTO5Pr+oqCgxduxY4erqKoyMjISTk5Po0KGD2LBhg2qZrMPC9+zZo9Vrl5CQIObOnStq1aolzMzMhJWVlWjZsqXw9/fPcfhw9hMqLlu2TLi6ugoTExPRunVrce3atRzbzs/r/Lr3LjY2VgwdOlTY29sLS0tL4ePjI+7evZvra7lx40bh4eEh5HJ5vk6o+N/XKa8T7a1evVpUqlRJmJiYiCZNmoizZ88KLy8v0blz53y8ukJkZGSIH374QbRu3VrY2NgIIyMjUalSJTF06FCNQ+uzDp/PfrLO7K9P9pNIBgQEiLp16wpTU1Ph5uYmFi9eLDZt2pRjuawTKuYmv9vIWrZFixbCzMxMWFtbiyZNmoiff/5ZdX9iYqLo37+/sLW1zXFCxfz+feD/J1TMDbIdPp+amio+++wzUa9ePWFlZSUsLCxEvXr1cpwMMq9Meb3PN2/eFD179hS2trbC1NRUVKtWTXzxxRe55iH9IhOCY4NElCk8PBzu7u5YunQppkyZInUcSSiVSpQrVw69evXKdZcPEZUunCNERHorJSUlxzyRrVu34sWLF2jbtq00oYioWHGOEBHprb///hsTJ05Enz59ULZsWVy+fBk//vgjateujT59+kgdj4iKAQshItJbbm5ucHV1xerVq/HixQuUKVMGgwcPxtdffy3pVe2JqPhwjhARERHpLc4RIiIiIr3FQoiIiIj0lt7NEVIqlXjy5AmsrKx45WEiIqISQgiBhIQElC9fPseJad+G3hVCT548eeOFMomIiEg3RUREoEKFCoW2Pb0rhKysrABkvpDW1tYSpyEiIqL8iI+Ph6urq+pzvLDoXSGUtTvM2tqahRAREVEJU9jTWjhZmoiIiPQWCyEiIiLSWyyEiIiISG+xECIiIiK9xUKIiIiI9BYLISIiItJbLISIiIhIb7EQIiIiIr3FQoiIiIj0FgshIiIi0luSFkKnT59G165dUb58echkMvz6669vXOfkyZNo2LAhTExMULlyZfj7+xd5TiIiIiqdJC2EkpKSUK9ePaxZsyZfyz948ADvvfce2rVrh6tXr+LTTz/F8OHDERgYWMRJiYiIqDSS9KKr7777Lt599918L79u3Tq4u7tj2bJlAIAaNWrgzJkzWLFiBXx8fIoqJhEREZVSJerq80FBQejYsaNGn4+PDz799FNpApVkUcHA7Z+AxCdSJ6ESSUgdgEos/u6Q9pRK4FZI0ezEKlGFUGRkJBwdHTX6HB0dER8fj+TkZJiZmeVYJzU1Fampqarb8fHxRZ5TpykzgL/nA0HzpE5CRET0Rk/jLTF0Vw+cuu9UJNsvUYVQQSxatAjz5vFDHwAQ/y/wW18g8oLUSYiIiN7owM1qGL6nG2KSLACkFMljlKhCyMnJCVFRURp9UVFRsLa2znU0CACmT5+OSZMmqW7Hx8fD1dW1SHPqpEd/Ab92A1Jfqvs8uwGtvwaMLCSLRSWZTOoAVFLJ+LtDbxYdk4wBc3YjKSkDAOBQzgzPogv/cUpUIdS8eXMcPnxYo++PP/5A8+bN81zHxMQEJiYmRR1Nt11aDpz+HBCKzNvmDkDXX4AKraXNRURElIdyVsDKle9ixIjf0KNHdSxf7g0PjzmF/jiSFkKJiYm4d++e6vaDBw9w9epVlClTBhUrVsT06dPx+PFjbN26FQAwatQofPfdd/j888/x0Ucf4c8//8Tu3btx6NAhqZ6C7gteAZyarL5tVxXo8ydg5SJdJiIiov9QKJTIyFDCxERdmgwb1gCurtbo1MkTCQkJRfK4kp5H6NKlS2jQoAEaNGgAAJg0aRIaNGiA2bNnAwCePn2Khw8fqpZ3d3fHoUOH8Mcff6BevXpYtmwZfvjhBx46n5ekqMyRoCw1BwGDLrMIIiIinRIREYeOHbdhypTfNfplMhl8fCpDVoS7U2VCCL06ljE+Ph42NjaIi4uDtbW11HGK1v6uQNjBzHbVD4Cue6TNQ0RE9B+7d9/CyJEH8fJl5mToQ4f6o0uXKjmWK6rP7xI1R4i08CpaXQQBmZOiiYiIdER8fComTDiCLVuuqfpcXa1hZWVcrDlYCJVW2c8TVL4lYOspXRYiIqJsgoIiMHDgfoSFxar6fH1rYe3a92Bnl/tR4EWFhVBpJARwNdv129ouky4LERHR/2VkKLFgwWl89dVpKBSZM3OsrIyxZk0XDBxYt0jnAuWFhVBp9O8fmredm0qTg4iI6P+eP3+Frl1/RlDQI1Vfixau+OmnnnB3t5Msl6RHjVERCf1F3a7WT7ocRERE/2drawpDw8yyQy6XYd68tjh1aoikRRDAQqj0UaQBobvVt9ssli4LERHR/8nlBti2rScaNnTGmTMfYfZsb1VhJCXuGittHp8FUuMy2x7vA9YVpc1DRER66dSpcJiZGaFJE/W56ypVssWlSyMkmQuUF+lLMSpcl1ep22480SQRERWvtDQFpk8/hnbttuDDD/ciISFV435dKoIAFkKlz/0D6rb7u9LlICIivRMSEoPmzX/E11+fhRBAWFgs1q69JHWs1+KusdIkNV7zto2HNDmIiEivCCGwceNlfPrpUSQnZ14t3sjIAAsWtMfkyS0kTvd6LIRKk+yjQeXqATo2/EhERKVPdHQSRoz4DQcOhKj6qlUrix07eqNhQ2cJk+UPC6HS5MERdbv2UOlyEBGRXggMvIchQw4gMjJR1TdqlBeWLfOBubmRhMnyj4VQafLwuLpd6R3pchARUakXFZWIHj12ISUlc1eYvb05Nm3qhq5dq0mcTDucLF1apCcDyc/Vt+1K1i8iERGVLI6Olvj66w4AAB8fT9y4MbrEFUEAR4RKjxs/AEKR2bavAxjIpc1DRESlilIpoFAoYWSk/nwZP74pKlSwRs+eNWBgUDLnpXJEqLS4+7O6zbNJExFRIXr6NAHvvrsds2b9qdFvYCBD7941S2wRBLAQKh2UGcCzy+rbnB9ERESF5MCBu6hTZy1+//0+li49hz//fCB1pELFXWOlweMzgOL/Z+70eB8w4NtKRERvJykpDZMn/47164NVfY6OlhImKhr8xCwNgleo21X7SJeDiIhKheDgJ+jffx9CQ9UH4XTvXg0//NAN9vbmEiYrfCyESoO4MHWbu8WIiKiAFAolvvnmHGbNOoGMDCUAwNzcCCtX+mD48IY6d52wwsBCqKR79QyIuZnZNjAELHX/LJ5ERKR7YmJeoU+fPTh5MlzV5+XljB07eqNq1bLSBStinCxd0l3foG43+ES6HEREVKLZ2JggMTENQOYVmqZPb4Vz54aV6iIIYCFU8kVmu6pvpQ7S5SAiohLNyEiO7dt7oUYNe5w44YeFCzvA2Lj0n5OOu8ZKMiE0L7RaXrev8EtERLojKCgC5uZGqFfPSdVXtWpZ3Lw5pkSfF0hbHBEqyZ6eV7edmgAmNtJlISKiEiEjQ4l5806idevN+PDDvXj1Kl3jfn0qggAWQiVbzHV129xRuhxERFQihIXFok2bzZg79xQUCoE7d2Lw/fcXpY4lKe4aK8kiTqnb9UdLl4OIiHSaEALbtl3HuHGHkZCQOSFaLpdhzhxvfPppM4nTSYuFUEmlVAAPDme25caASytp8xARkU6KjU3GqFGHsHv3LVWfp6cdfvqpF5o1qyBhMt3AQqikiroEpL7MbLu9CxhbSRqHiIh0z8mT4Rg0aD8ePYpX9Q0dWh+rVnWGlZWJhMl0Bwuhkipkl7pdobV0OYiISCc9fZoAH5+fkJamAADY2Zli/fr30adPLYmT6RZOli6pbvygbrv5SJeDiIh0krOzFebM8QYAtGvnhuvXR7MIygVHhEoiRRqgzHa4Y1n+YhMR6TshBJRKAblcPcYxdWpLuLpaY8CAunp3WHx+cUSoJHpwFMhIyWy7tMo8FzoREemt6Ogk9Oy5C/Pnn9bol8sNMGhQPRZBr8ERoZIo7KC6XWOAdDmIiEhygYH3MGTIAURGJuLgwVB06uSJ5s1dpY5VYrAQKolC96jbbp2ly0FERJJJScnA9OnHsHKl+ioDdnZmqvMEUf6wECppUl6qD5sHABs3iYIQEZFUbtyIwoAB+3DjxjNVn4+PJ/z9e8DJyVLCZCUPC6GS5tJSdbvGQOlyEBFRsVMqBb799jymTj2G1NTMw+JNTORYsuQdjBvXhHOBCoCFUEkTHqhuV/1AuhxERFSsnj9/hQED9iEw8L6qr04dB+zY0Ru1aztImKxk41FjJUlSJBAVrL7t2U26LEREVKwsLIzx+HGC6vbEic1w4cIIFkFviYVQSfL3AnW78ec8bJ6ISI+Ymhpix45ecHe3RWDgQCxf7gNTU+7YeVt8BUuS+wfUbY/3pMtBRERFLjj4CSwsjFG9ur2qr04dR4SGjoehIccxCgtfyZJCCCAhQn3buZl0WYiIqMgoFEosXnwGzZr9iA8/3IvU1AyN+1kEFS6+miXFv39o3pYbS5ODiIiKTEREHDp02Ipp044jI0OJq1cj8f33F6WOVapx11hJcW2tut3+W+lyEBFRkdi9+xZGjjyIly8zL6EkkwHTprXC2LFNJE5WurEQKglSYoGwQ5lt0zJA3ZHS5iEiokITH5+KCROOYMuWa6o+V1drbNvWE97ebtIF0xMshEqCkF3qq81X6wfIjaTNQ0REhSIoKAIDB+5HWFisqs/XtxbWrn0PdnZmEibTHyyESoLQvep29Q+ly0FERIXm8eN4tG27BWlpmWeItrIyxpo1XTBwYF3IeHqUYsPJ0rou+Tnw8Fhm28wecGkhbR4iIioULi7WmDKlOQCgRQtXXLs2CoMG1WMRVMw4IqTr7geo257dABlrVyKikkgIAQAahc7cuW1RsaINhg1ryMPiJcJXXdc9PK5ul6svWQwiIiq42Nhk9Ou3F8uWBWn0GxnJMXJkIxZBEuKIkK67s13d9ugiXQ4iIiqQkyfDMWjQfjx6FI/9+++gQwd3NGjgLHUs+j+WoCWJjYfUCYiIKJ/S0hSYNu0Y2rffgkeP4gEAlpbGiIxMlDgZZccRIV0WH6F5mxPoiIhKhJCQGPTvvw+XLz9V9bVr54atW3uiQgVrCZPRf7EQ0mUXl6jb9cdKl4OIiPJFCIENG4IxcWIgkpMzrxFmZGSABQvaY/LkFjAw4BdaXcNCSJeFHVS3642WLgcREb3RixfJGDr0AAICQlR91aqVxY4dvdGwIecE6SoWQroq6goQH57ZNjQF7GtJGoeIiF7PxESOu3djVLdHj26Eb77pBHNzXg1Al3GytK7KOokiANQZIV0OIiLKFwsLY2zf3gvly1shIKAfvv/+PRZBJQBHhHTV+YXqdpVe0uUgIqJc3bgRBQsLY3h42Kn6GjUqj7CwCTAx4cdrScERIV2Ungykvsxsm5YBXFpLGoeIiNSUSoFVq/5G48YbMWDAPmRkKDXuZxFUsrAQ0kUPDqvbDvUBA7lkUYiISO3p0wS8++52fPppIFJTFfj770dYu/ai1LHoLUheCK1ZswZubm4wNTVF06ZNceHChdcuv3LlSlSrVg1mZmZwdXXFxIkTkZKSUkxpi8m/f6jb9nWky0FERCoHDtxFnTpr8fvv91V9Eyc2w4gRXhKmorcl6fjdrl27MGnSJKxbtw5NmzbFypUr4ePjg5CQEDg4OORYfseOHZg2bRo2bdqEFi1aIDQ0FEOGDIFMJsPy5csleAZFIC0BuPGD+nbDT6TLQkRESEpKw+TJv2P9+mBVn7OzJfz9e6BTJ08Jk1FhkHREaPny5RgxYgSGDh2KmjVrYt26dTA3N8emTZtyXf7cuXNo2bIl+vfvDzc3N3Tq1AkffvjhG0eRSpSDvoBQZLZd2wE27tLmISLSY8HBT9Cw4QaNIqhHj+q4fn00i6BSQrJCKC0tDcHBwejYsaM6jIEBOnbsiKCgoFzXadGiBYKDg1WFT1hYGA4fPowuXfK+GGlqairi4+M1fnTW6WnAgyOZbbkx0H61tHmIiPRYREQcWrTYhNDQ5wAAc3MjbNzYFfv29YW9vbnE6aiwSFYIxcTEQKFQwNHRUaPf0dERkZGRua7Tv39/fPnll2jVqhWMjIzg6emJtm3bYsaMGXk+zqJFi2BjY6P6cXV1LdTnUSiEEjg5Bbi4WN3XbhVgX1u6TEREes7V1QZjxjQCAHh5OePKlZEYPrwhZLzuY6ki+WRpbZw8eRILFy7E999/j8uXL2Pfvn04dOgQvvrqqzzXmT59OuLi4lQ/EREReS4riZdhwO72QPAydZ/XJKDeKOkyERHpKSGExu1Fizpi+fJOOHduGKpWLStRKipKkk2Wtre3h1wuR1RUlEZ/VFQUnJyccl3niy++wKBBgzB8+HAAQJ06dZCUlISPP/4YM2fOhIFBzrrOxMQEJiYmhf8E3pZQAne2Ayc+AVJi1f31RgFtl+W9HhERFbr4+FRMmHAETZq4YMyYxqp+U1NDTJzYXMJkVNQkGxEyNjaGl5cXjh8/rupTKpU4fvw4mjfP/Zfu1atXOYoduTzzHDv/reJ1llACV9cCG92BI4PVRZCxNdDjN6DjWmnzERHpmaCgCNSvvw5btlzD5Mm/486daKkjUTGS9PD5SZMmwc/PD40aNUKTJk2wcuVKJCUlYejQoQCAwYMHw8XFBYsWLQIAdO3aFcuXL0eDBg3QtGlT3Lt3D1988QW6du2qKoh03vGxwLV1mn2VOgHvbgEsch8JIyKiwpeRocT8+acxf/5pKBSZX6aNjAxw/34satQoJ3E6Ki6SFkK+vr6Ijo7G7NmzERkZifr16+Po0aOqCdQPHz7UGAGaNWsWZDIZZs2ahcePH6NcuXLo2rUrFixYINVT0M6fn2gWQRXbAw0+ASp3ky4TEZEeCguLxcCB+xAU9EjV16KFK376qSfc3e1esyaVNjJRYvYpFY74+HjY2NggLi4O1tbWxffA0deBrfXUt1stAppOK77HJyIiCCGwdes1jBt3BImJaQAAuVyG2bO9MWNGaxgalqhjiPRKUX1+88pwxeXkZHW79jAWQURExezlyxSMHHkQu3ffUvV5eNhh+/ZeaNasgoTJSEoshIrDv8eAh8cy2waGPCqMiEgCMhlw/rx6V9iQIfWxenVnWFnp4JHFVGw4BlgcTk1Rt1vOB0xspMtCRKSnbGxMsW1bT9jbm2P37g+weXN3FkHEEaEi9+8xIPpaZtvaDWg05bWLExFR4QgJiYGFhTEqVFDPJ2nduhLCwz+BhYWxhMlIl3BEqKhdWKRuN/4MMCghh/kTEZVQQgisX38JDRqsx+DB+6FUah4TxCKIsmMhVJSSIoGHf6pv1xwsXRYiIj0QHZ2EHj12YdSoQ0hOzsCJE+HYsCH4zSuS3uKusaJ0PttoUC0/wNhSuixERKVcYOA9DBlyAJGRiaq+UaO8MHhwvdesRfqOhVBRSYoErqxW3270mXRZiIhKsZSUDEyffgwrV55X9dnbm2PTpm7o2rWahMmoJGAhVFSub1S3nZoA9rWky0JEVErduBGFAQP24caNZ6o+Hx9P+Pv3gJMTR+HpzVgIFZXHZ9Rt72+ky0FEVEr9++9LNG68EampCgCAiYkcS5a8g3HjmsDAQCZxOiopOFm6KCjSgYj/T5I2sQFcWkmbh4ioFKpUyVY1/6dOHQdcuvQxJkxoyiKItMIRoaJwYyOgzMhsu3XOPJ0pEREVuhUrfFCpkg0mT24BU1N+pJH2OCJUFE5PVbdr+UmXg4iolEhKSsOoUQfh739Vo9/CwhgzZ7ZhEUQFxt+cwvYqGsh4pb7t1lm6LEREpUBw8BMMGLAPISHPsX37DbRuXRGenmWkjkWlBEeECtulZYBQZrar+XK3GBFRASkUSixefAbNmv2IkJDnAAClUuDmzWdvWJMo/zgiVNguLla3G/PcQUREBREREYdBg/bj1Kl/VX1eXs7YsaM3qlYtK2EyKm1YCBWm6OvqtswAcPSSLgsRUQm1e/ctjBx5EC9fpgDIHFifNq0V5s5tC2NjXq+RChcLocJ0IdtoUKV3pMtBRFQCJSSkYvz4I9iy5Zqqz9XVGtu29YS3t5t0wahUYyFUWFJigZBdmW2ZHOiyXdo8REQlTGqqAr//fl9129e3FtaufQ92dmYSpqLSjpOlC8uNHwGReXZT1BkOmHEfNhGRNuztzbFlSw9YW5tg69Ye+Pnn3iyCqMhxRKiwnM42MbpqH+lyEBGVEGFhsbCwMIKjo/qaYO+844l///0UtramEiYjfcIRocIghObtiu2lyUFEVAIIIbBly1XUq7cOH30UAPGf/0NZBFFxYiFUGB6f1bzNcwcREeUqNjYZ/frtxZAhB5CYmIbDh//B5s1XpY5Feoy7xgrD47/U7XqjpMtBRKTDTp4Mx6BB+/HoUbyqb8iQ+ujTp6aEqUjfsRAqDE//VrcdG0uXg4hIB6WlKTB79gksWXJWNZPAzs4U69e/jz59akkbjvQeC6HC8CJE3S7fTLocREQ65u7dGAwYsA+XLz9V9bVr54atW3uiQgVrCZMRZWIh9LaEABIfqW+XqSFdFiIiHRIWFouGDdcjOTkDAGBkZIAFC9pj8uQWMDDgXErSDZws/baeXQbSkzLbTo05UZqI6P88POzQq1fml8Nq1cri77+H47PPWrIIIp3CEaG39eCoul21r3Q5iIh00Jo1XVCpkg1mzmwDc3MjqeMQ5fBWI0IpKSmFlaPkirmhbpvYShaDiEhKKSkZmDjxKPbsuaXRb2NjigULOrAIIp2ldSGkVCrx1VdfwcXFBZaWlggLCwMAfPHFF/jxxx8LPaDOu/+buu3EI8aISP/cuBGFJk02YuXK8/j444OIiIiTOhJRvmldCM2fPx/+/v5YsmQJjI2NVf21a9fGDz/8UKjhdJ4iDch4pb5tX1u6LERExUypFFi16m80brwRN248AwAkJ6fj0qUnEicjyj+tC6GtW7diw4YNGDBgAORyuaq/Xr16uHv3bqGG03mRF9VtCyfAQJ73skREpcjTpwno0mU7Pv00EKmpmRecrlPHAZcufYyePXn0LJUcWk+Wfvz4MSpXrpyjX6lUIj09vVBClRiRF9TtWkMki0FEVJwOHLiL4cN/Q0yMekR84sRmWLiwA0xNeQwOlSxa/8bWrFkTf/31FypVqqTR/8svv6BBgwaFFqxECNmlbru/J10OIqJikJSUhsmTf8f69cGqPmdnS/j790CnTp4SJiMqOK0LodmzZ8PPzw+PHz+GUqnEvn37EBISgq1bt+LgwYNFkVF3ybK9fOXqSpeDiKgYxMenYu/eO6rbPXpUx8aNXWFvby5hKqK3o/Ucoe7du+O3337DsWPHYGFhgdmzZ+POnTv47bff8M477xRFRt2VHKNum/BU8URUujk7W+GHH7rC3NwIGzd2xb59fVkEUYknEyLrEnj6IT4+HjY2NoiLi4O19VsUL8oMYMX/z4th6wkMu1c4AYmIdERERBwsLIxRpoyZRv+zZ0lwcLCQKBXpq0L7/P4PrUeEPDw88Pz58xz9L1++hIeHR6GEKhGyX2jVnrvFiKh02b37FurWXYeRIw/iv9+XWQRRaaJ1IRQeHg6FQpGjPzU1FY8fPy6UUCVCwkN1W5kmXQ4iokIUH5+KIUN+ha/vL3j5MgW//HIbO3bcePOKRCVUvidLBwQEqNqBgYGwsbFR3VYoFDh+/Djc3NwKNZxOi8l2GvkqH0iXg4iokAQFRWDAgH148OClqs/Xtxa6dKkiXSiiIpbvQqhHjx4AAJlMBj8/P437jIyM4ObmhmXLlhVqOJ0WG6pu2+Y8rxIRUUmRkaHEggWn8dVXp6FQZO4Gs7Iyxpo1XTBwYF3IZLxaPJVe+S6ElEolAMDd3R0XL16Evb19kYUqEW5mu65amarS5SAiegthYbEYOHAfgoIeqfpatHDFTz/1hLu7nYTJiIqH1ucRevDgQVHkKHmyTx40KyddDiKiArp37wUaNlyPhITMeY5yuQyzZ3tjxozWMDTUegopUYlUoHOhJyUl4dSpU3j48CHS0jQnCk+YMKFQguk0RRqAbIUQh42JqATy9LRDhw4e+PXXu/DwsMP27b3QrFkFqWMRFSutC6ErV66gS5cuePXqFZKSklCmTBnExMTA3NwcDg4O+lEIxYWr22WqSxaDiOhtyGQybNzYFZUq2eCrr9rByspE6khExU7rsc+JEyeia9euiI2NhZmZGf7++2/8+++/8PLywjfffFMUGXVPQoS6bWwlXQ4ionxKS1Ng2rRjOHQoVKPf3t4cK1d2ZhFEekvrQujq1auYPHkyDAwMIJfLkZqaCldXVyxZsgQzZswoioy6J+mJuu3aTrocRET5EBISg+bNf8TixWfx0UcBiIpKlDoSkc7QuhAyMjKCgUHmag4ODnj4MPPEgjY2NoiIiHjdqqVH9rNKm/CoCiLSTUIIrF9/CQ0arMfly08BALGxyTh7Vk/+rybKB63nCDVo0AAXL15ElSpV4O3tjdmzZyMmJgbbtm1D7dq1iyKj7sm+a8zcQbocRER5iI5OwvDhvyEgQP3FrVq1stixozcaNnSWMBmRbtF6RGjhwoVwds78I1qwYAHs7OwwevRoREdHY/369YUeUCdlJKvbZWtKl4OIKBeBgfdQt+46jSJo9OhGuHx5JIsgov/QekSoUaNGqraDgwOOHj1aqIFKhORodZtHjRGRjkhJycD06cewcuV5VZ+9vTk2beqGrl2rSZiMSHcV2hmzLl++jPfff7+wNqfbkqIy/5WbAKa2kkYhIsry7FkSNm++qrrduXNl3LgxmkUQ0WtoVQgFBgZiypQpmDFjBsLCwgAAd+/eRY8ePdC4cWPVZThKvVfPMv/lGaWJSIdUrGiDtWvfg4mJHKtXd8bhw/3h5GQpdSwinZbvXWM//vgjRowYgTJlyiA2NhY//PADli9fjvHjx8PX1xc3b95EjRo1ijKrblCkASnPM9uW3NdORNJ5+jQBFhbGsLZWnwPoww/roFWrinB1tZEwGVHJke8RoVWrVmHx4sWIiYnB7t27ERMTg++//x43btzAunXr9KMIAoDk5+q2BQshIpLGgQN3UbfuOkyYcCTHfSyCiPIv34XQ/fv30adPHwBAr169YGhoiKVLl6JCBT27Ls2rKHXb3FG6HESkl5KS0jBq1EH06LELMTGvsGXLNezde1vqWEQlVr53jSUnJ8Pc3BxA5vVpTExMVIfR65Wkp+q2ia1kMYhI/wQHP0H//vsQGqoeme7Rozq8vd2kC0VUwml1+PwPP/wAS8vMiXcZGRnw9/eHvb29xjKl/qKr4b+r20YW0uUgIr2hUCjxzTfnMGvWCWRkZB6UYm5uhFWrOmPYsAaQyWQSJyQquWRCCJGfBd3c3N74xyaTyVRHk+XXmjVrsHTpUkRGRqJevXr49ttv0aRJkzyXf/nyJWbOnIl9+/bhxYsXqFSpElauXIkuXbrk6/Hi4+NhY2ODuLg4WFtba5UVAPD7CODGD5nt3kcBNx/tt0FElE8REXEYNGg/Tp36V9Xn5eWMHTt6o2rVshImIypeb/35nYd8jwiFh4cX2oNm2bVrFyZNmoR169ahadOmWLlyJXx8fBASEgIHh5yXrkhLS8M777wDBwcH/PLLL3BxccG///4LW1vbQs+Wp7s/q9tl9GSCOBFJIjT0OZo2/QEvX6YAAGQyYNq0Vpg7ty2MjeUSpyMqHbQ+s3RhWr58OUaMGIGhQ4cCANatW4dDhw5h06ZNmDZtWo7lN23ahBcvXuDcuXMwMjICkDlSVayMLIH0pMy2pUvxPjYR6ZXKlcugaVMXBAbeh6urNbZt68n5QESFrNDOLK2ttLQ0BAcHo2PHjuowBgbo2LEjgoKCcl0nICAAzZs3x9ixY+Ho6IjatWtj4cKFUCgUxRM6NV7zqDEDfiMjoqJjYCDD5s3d8fHHDXHt2igWQURFQLIRoZiYGCgUCjg6ah6C7ujoiLt37+a6TlhYGP78808MGDAAhw8fxr179zBmzBikp6djzpw5ua6TmpqK1NRU1e34+PiCh85+1fnq/Qu+HSKi/8jIUGLBgtNo3boS2rd3V/U7O1th/fquEiYjKt0k3TWmLaVSCQcHB2zYsAFyuRxeXl54/Pgxli5dmmchtGjRIsybN69wAkRfV7dtPQtnm0Sk98LCYjFw4D4EBT2Ci4sVrl8fjTJlzKSORaQXJNs1Zm9vD7lcjqioKI3+qKgoODk55bqOs7MzqlatCrlcvUuqRo0aiIyMRFpaWq7rTJ8+HXFxcaqfiIiIXJfLl9gQdduqYsG3Q0QEQAiBrVuvoX79dQgKegQAiIxMxIkTDyRORqQ/ClQI3b9/H7NmzcKHH36IZ88yL0B65MgR3Lp1K9/bMDY2hpeXF44fP67qUyqVOH78OJo3b57rOi1btsS9e/c0Lu4aGhoKZ2dnGBsb57qOiYkJrK2tNX4KLC7bf052VQq+HSLSe7GxyejXby/8/H5FQkLmFzkPDzucOfMReveuKXE6Iv2hdSF06tQp1KlTB+fPn8e+ffuQmJgIALh27Vqeu6fyMmnSJGzcuBFbtmzBnTt3MHr0aCQlJamOIhs8eDCmT5+uWn706NF48eIFPvnkE4SGhuLQoUNYuHAhxo4dq+3TKJjoq+q2U97nOiIiep2TJ8NRt+467N6t/vI4ZEh9XL06Es2a6dlli4gkpvUcoWnTpmH+/PmYNGkSrKysVP3t27fHd999p9W2fH19ER0djdmzZyMyMhL169fH0aNHVROoHz58CAMDda3m6uqKwMBATJw4EXXr1oWLiws++eQTTJ06Vdunob2MFCD6Rmbbxh0w4v57ItJOWpoCc+acwOLFZ5F1KltbW1Ns2PA++vSpJW04Ij2V7zNLZ7G0tMSNGzfg7u4OKysrXLt2DR4eHggPD0f16tWRkpJSVFkLRYHPTPngCLDv/2evrtoH6Lq7aAISUakVFhaLunXXIikpHQDQtq0btm7twavFE+VDUZ1ZWutdY7a2tnj69GmO/itXrsDFpRSfYDAm2/wnu6rS5SCiEsvDww6rVnWGkZEBlizpiOPHB7MIIpKY1rvG+vXrh6lTp2LPnj2QyWRQKpU4e/YspkyZgsGDBxdFRt0QeVHddmwkXQ4iKjFiYl7B3NwI5uZGqr6PPmoAb283VK5cRsJkRJRF6xGhhQsXonr16nB1dUViYiJq1qyJNm3aoEWLFpg1a1ZRZNQNDw6p2/bcl09ErxcYeA916qzFZ5/9rtEvk8lYBBHpEK3nCGV5+PAhbt68icTERDRo0ABVqpSMw8kLtI9RCGB5tppxkjLz6odERP+RkpKB6dOPYeXK86q+gwc/xHvvcZc60duQ/OrzWc6cOYNWrVqhYsWKqFhRT04qmPxc3Ta1YxFERLm6cSMKAwbsw40bz1R9nTtXhpdXeQlTEdHraL1rrH379nB3d8eMGTNw+/btosike+LC1G1LnuODiDQplQKrVv2Nxo03qoogExM5Vq/ujMOH+8PJyVLihESUF60LoSdPnmDy5Mk4deoUateujfr162Pp0qV49OhRUeTTDYmP1W1rN8liEJHuefo0AV26bMennwYiNVUBAKhTxwGXLn2M8eObQsYRZCKdpnUhZG9vj3HjxuHs2bO4f/8++vTpgy1btsDNzQ3t27cviozSe6Ue5oajl3Q5iEinhITEoG7ddQgMvK/qmzixGS5cGIHatR0kTEZE+fVWF111d3fHtGnT8PXXX6NOnTo4depUYeXSLf9mO+rDrrJ0OYhIp1SuXAY1a5YDADg7WyIwcCCWL/eBqanW0y+JSCIFLoTOnj2LMWPGwNnZGf3790ft2rVx6NChN69YEgn1RV5Rrp50OYhIp8jlBti2rScGDaqL69dHo1MnT6kjEZGWtP7aMn36dOzcuRNPnjzBO++8g1WrVqF79+4wNzcviny64d6v6naZ6pLFICLpKBRKfPPNObRuXQktWriq+itWtMHWrT0lTEZEb0PrQuj06dP47LPP0LdvX9jb2xdFJh0mAww45E2kbyIi4jBo0H6cOvUv3N1tcfXqKFhbm0gdi4gKgdaf6mfPni2KHLpLkaZuG1lIl4OIJLF79y2MHHkQL19mXlA6PPwlfv/9Pj74oKbEyYioMOSrEAoICMC7774LIyMjBAQEvHbZbt26FUownZEUqW7L+Q2QSF/Ex6diwoQj2LLlmqrP1dUa27b1hLe3m3TBiKhQ5asQ6tGjByIjI+Hg4IAePXrkuZxMJoNCoSisbLohPlzdrtZXshhEVHyCgiIwcOB+hIXFqvp8fWth7dr3YGdnJmEyIips+SqElEplrm29kJDtZIqGpXhCOBEhI0OJBQtO46uvTkOhyLwMo5WVMdas6YKBA+vy5IhEpZDWh89v3boVqampOfrT0tKwdevWQgmlU57fVLfNykqXg4iK3P37L7Bo0RlVEdSihSuuXRuFQYPqsQgiKqW0LoSGDh2KuLi4HP0JCQkYOnRooYTSKfEP1W0rXmeMqDSrVs0eS5a8A7lchnnz2uLUqSFwd7eTOhYRFSGtjxoTQuT6zejRo0ewsbEplFA6RZFt9KtMDelyEFGhi41Nhrm5EUxM1P8Vjh/fBO3bu/MSGUR6It+FUIMGDSCTySCTydChQwcYGqpXVSgUePDgATp37lwkISX14o66beWa93JEVKKcPBmOQYP2o1+/Wli6tJOqXyaTsQgi0iP5LoSyjha7evUqfHx8YGlpqbrP2NgYbm5u6N27d6EHlFzKS3Xb2EqyGERUONLSFJgz5wQWLz4LIYBvvglC586V0aGDh9TRiEgC+S6E5syZAwBwc3ODr68vTE1NiyyUTjF3ABIfZbaNeNQYUUkWEhKD/v334fLlp6q+du3cUK2avp0ln4iyaD1HyM/Pryhy6K5nlzP/NbaWNgcRFZgQAhs2BGPixEAkJ2cAAIyMDLBgQXtMntwCBgY8IoxIX+WrECpTpgxCQ0Nhb28POzu71x5G+uLFi0ILp1MM5FInIKICiI5OwvDhvyEgIETVV61aWezY0RsNGzpLmIyIdEG+CqEVK1bAyspK1dar82mY2ACpcUBK7JuXJSKdEhISg7ZttyAyMlHVN3p0I3zzTSeYmxtJmIyIdEW+CqHsu8OGDBlSVFl0U+r/z5nk0EDaHESkNQ8PO7i6WiMyMhH29ubYtKkbunatJnUsItIhWp9Q8fLly7hx44bq9oEDB9CjRw/MmDEDaWlpr1mzBEpTf4tE6kvJYhBRwRgZybF9ey/06lUDN26MZhFERDloXQiNHDkSoaGhAICwsDD4+vrC3Nwce/bsweeff17oASWV/crzPHSeSKcplQKrV5/HlStPNfqrVCmLvXv7wsnJMo81iUifaV0IhYaGon79+gCAPXv2wNvbGzt27IC/vz/27t1b2PmklZagbhtwPgGRrnr6NAFdumzHJ58cRf/++/DqVbrUkYiohNC6EBJCqK5Af+zYMXTp0gUA4OrqipiYmMJNJ7WkbN8sXdtJl4OI8nTgwF3UrbsOgYH3AQB378bgyJF/JE5FRCWF1ucRatSoEebPn4+OHTvi1KlTWLt2LQDgwYMHcHR0LPSA0hLqZvy/0sUgohySktIwefLvWL8+WNXn7GwJf/8e6NTJU8JkRFSSaF0IrVy5EgMGDMCvv/6KmTNnonLlygCAX375BS1atCj0gJLKSFG3HRtJl4OINAQHP0H//vsQGvpc1dejR3Vs3NgV9vY8AzwR5Z/WhVDdunU1jhrLsnTpUsjlpeykg1mHzgOAoZl0OYgIAKBQKLF06Tl88cUJZGRk7qI3NzfCypU+GD68oX6d44yICoXWhVCW4OBg3LmTeWX2mjVromHDhoUWSmckPZE6ARFlc/dujEYR5OXljB07eqNq1bISJyOikkrrQujZs2fw9fXFqVOnYGtrCwB4+fIl2rVrh507d6JcuXKFnVE6htmG2OXG0uUgIgBArVoO+Oqrdpgx4zimTWuFuXPbwti4lI1EE1Gx0vqosfHjxyMxMRG3bt3Cixcv8OLFC9y8eRPx8fGYMGFCUWSUTtQlddvSRbocRHoqISFVNfqT5bPPWuDChRFYuLADiyAiemtaF0JHjx7F999/jxo1aqj6atasiTVr1uDIkSOFGk5y2Ysfocx7OSIqdEFBEahffz3mzz+t0S+XG6BRo/ISpSKi0kbrQkipVMLIKOfJBY2MjFTnFyo1lNlOymbuIF0OIj2SkaHEvHkn0br1ZoSFxeKrr07j3LkIqWMRUSmldSHUvn17fPLJJ3jyRD2R+PHjx5g4cSI6dOhQqOEkp8h27TTOESIqcmFhsWjTZjPmzj0FhSLzPF7NmlWAszMvj0FERUPrQui7775DfHw83Nzc4OnpCU9PT7i7uyM+Ph7ffvttUWSUTkqsus1CiKjICCGwdes11K+/DkFBjwAAcrkM8+a1xalTQ+DubidtQCIqtbQ+aszV1RWXL1/G8ePHVYfP16hRAx07diz0cJIL2aluG7AQIioKsbHJGD36EHbtuqXq8/Cww/btvdCsWQUJkxGRPtCqENq1axcCAgKQlpaGDh06YPz48UWVSzeUqQG8yCz2YMWjxogKW0hIDN55ZxsiIuJVfUOG1Mfq1Z1hZWUiYTIi0hf5LoTWrl2LsWPHokqVKjAzM8O+fftw//59LF26tCjzSSv7kWJGFtLlICqlKlWyha2tKSIi4mFnZ4r1699Hnz61pI5FRHok33OEvvvuO8yZMwchISG4evUqtmzZgu+//74os0kvPSHzX55DiKhImJoaYseO3ujSpQquXx/NIoiIil2+C6GwsDD4+fmpbvfv3x8ZGRl4+vRpkQTTCSkvMv81LSNtDqJSQAiBDRuCcft2tEZ/7doOOHSoPypUsJYoGRHps3wXQqmpqbCwUO8eMjAwgLGxMZKTk4skmOSUGeqrzxtbSZuFqISLjk5Cjx67MHLkQfTvvxepqRlSRyIiAqDlZOkvvvgC5ubq62+lpaVhwYIFsLGxUfUtX7688NJJKfuh84pU6XIQlXCBgfcwZMgBREYmAgCuXYvCwYOh6N27psTJiIi0KITatGmDkJAQjb4WLVogLCxMdVsmkxVeMqm9eqZuKxXS5SAqoVJSMjBt2jGsWnVe1Wdvb45Nm7qha9dqEiYjIlLLdyF08uTJIoyhg1JfqtsWTpLFICqJbtyIQv/++3DzpvoLhY+PJ/z9e8DJiWeJJiLdofUJFfXGy/vqdlkO4RPlh1Ip8O235zF16jGkpmaOpJqYyLFkyTsYN64JDAxK0agxEZUKLITykvhI3eY5hIjy5caNKEya9DuUyszrhNWp44AdO3qjdm1etJiIdJPW1xrTG9lPpmhdSbocRCVIvXpOmDGjFQBg4sRmuHBhBIsgItJpHBHKy+Mz6ratp3Q5iHTYq1fpMDU11NjlNXu2Nzp18kTr1vwCQUS6jyNCeUnItmuM5xEiyiE4+AkaNFiPZcvOafQbGclZBBFRiVGgQuivv/7CwIED0bx5czx+/BgAsG3bNpw5c+YNa5YgZmXVbauK0uUg0jEKhRKLF59Bs2Y/IjT0OWbO/BOXL5fiM8wTUammdSG0d+9e+Pj4wMzMDFeuXEFqaubJBuPi4rBw4cJCDyiZ7EeNZS+KiPRYREQcOnTYimnTjiMjI3MeXd26jrC0NJY4GRFRwWhdCM2fPx/r1q3Dxo0bYWRkpOpv2bIlLl++XKjhJJWelPmv3ASQcQ8i0e7dt1C37jqcOvUvAEAmA6ZPb4Vz54ahalV+WSCikknrydIhISFo06ZNjn4bGxu8fPmyMDJJLyVWfUJFuyqSRiGSWnx8KiZMOIItW66p+lxdrbFtW094e7tJF4yIqBBoXQg5OTnh3r17cHNz0+g/c+YMPDw8CiuXtB4cUbfL1ZMuB5HEQkJi0KXLDoSFqa+95+tbC+vWvQ9bW1MJkxERFQ6t9/mMGDECn3zyCc6fPw+ZTIYnT55g+/btmDJlCkaPHl0UGYvf9Q3qdgVv6XIQSaxCBWsYGmb+N2FlZYytW3vg5597swgiolJD60Jo2rRp6N+/Pzp06IDExES0adMGw4cPx8iRIzF+/PgChVizZg3c3NxgamqKpk2b4sKFC/lab+fOnZDJZOjRo0eBHjdP0epdAHBsVLjbJipBLCyMsWNHL7Rt64Zr10Zh0KB6peviykSk92RCCFGQFdPS0nDv3j0kJiaiZs2asLQs2IUUd+3ahcGDB2PdunVo2rQpVq5ciT179iAkJAQODnmfkTY8PBytWrWCh4cHypQpg19//TVfjxcfHw8bGxvExcXB2to65wJCAMuz1YeTFJwsTXpBCIFt266jZUtXeHqWyXEfCyAiktIbP78LqMCf8MbGxqhZsyaaNGlS4CIIAJYvX44RI0Zg6NChqFmzJtatWwdzc3Ns2rQpz3UUCgUGDBiAefPmFf68pKhL6raFM4sg0guxscno128v/Px+xYAB+5CertC4n0UQEZVWWk+Wbteu3Wv/U/zzzz/zva20tDQEBwdj+vTpqj4DAwN07NgRQUFBea735ZdfwsHBAcOGDcNff/312sdITU1VnesIyKwoX+tRtu3VH/v6ZYlKgZMnwzFo0H48epT5t3H+/GMcPBiKnj1rSJyMiKjoaV0I1a9fX+N2eno6rl69ips3b8LPz0+rbcXExEChUMDR0VGj39HREXfv3s11nTNnzuDHH3/E1atX8/UYixYtwrx58/If6vTn6rZr2/yvR1TCpKUpMHv2CSxZchZZO8jt7EyxYUNXFkFEpDe0LoRWrFiRa//cuXORmJj41oFeJyEhAYMGDcLGjRthb2+fr3WmT5+OSZMmqW7Hx8fD1dU17xVEtl0Czk0LGpVIp4WExKB//30al8Zo184NW7f2RIUKhbfvnYhI1xXa1ecHDhyIJk2a4Jtvvsn3Ovb29pDL5YiKitLoj4qKgpOTU47l79+/j/DwcHTt2lXVp1Rmnubf0NAQISEh8PTUvFK8iYkJTExM8hco9p7mbYNCe3mIdIIQAhs2BGPixEAkJ2cAAIyMDLBgQXtMntxC4yryRET6oNA+6YOCgmBqqt25RYyNjeHl5YXjx4+rDoFXKpU4fvw4xo0bl2P56tWr48aNGxp9s2bNQkJCAlatWvX6kZ78uPmjut3iy7fbFpEOunIlEqNGHVLdrlatLHbs6I2GDZ0lTEVEJB2tC6FevXpp3BZC4OnTp7h06RK++OILrQNMmjQJfn5+aNSoEZo0aYKVK1ciKSkJQ4cOBQAMHjwYLi4uWLRoEUxNTVG7dm2N9W1tbQEgR3+BPD6jbjt6vf32iHRMw4bOmDSpGZYv/xujRzfCN990grm50ZtXJCIqpbQuhGxsbDRuGxgYoFq1avjyyy/RqVMnrQP4+voiOjoas2fPRmRkJOrXr4+jR4+qJlA/fPgQBgbFdAj7q2h1275W8TwmURFKTc2AsbFc40jPhQs7oHPnynjnHc/XrElEpB+0OqGiQqHA2bNnUadOHdjZ2RVlriLz2hMyrTIHMpIz2xPTOUeISrQbN6LQv/8+jB7dCGPGNJY6DhHRW9GJEyrK5XJ06tSp9Fxl/r+yiiCARRCVWEqlwKpVf6Nx4424efMZJk/+HbdvR795RSIiPaT1p33t2rURFhYGd3f3osgjnYzUNy9DpOOePk3A0KEHEBh4X9VXpUqZ16xBRKTftJ58M3/+fEyZMgUHDx7E06dPER8fr/FTYsWpPzhQtY90OYgK6MCBu6hbd51GETRxYjNcuDACNWuWkzAZEZHuyveI0JdffonJkyejS5cuAIBu3bppTMDMuiijQqHIaxO6LTlG3X71TLocRFpKSkrD5Mm/Y/36YFWfs7Ml/P17oFMnTogmInqdfBdC8+bNw6hRo3DixImizCOdl2HqdsUO0uUg0kJo6HN07fozQkOfq/p69KiOjRu7wt7eXMJkREQlQ74LoayDy7y9vYssjKQUKep2WoJ0OYi04OhogbS0zFFYc3MjrFrVGcOGNeDV4omI8kmrOUKl+j/X7JfXKFdXuhxEWrCxMcVPP/VE06YuuHJlJIYPb1i6/06JiAqZVkeNVa1a9Y3/yb548eKtAkkm+/Myscl7OSIJ7dlzC82aVYCrq/p3tGXLiggKGsYCiIioALQqhObNm5fjzNKlRrJ6jgVsPKTLQZSL+PhUTJhwBFu2XEPbtm44dmwQ5HL1gC6LICKigtGqEOrXrx8cHByKKou0FNnOI2So3cVjiYpSUFAEBg7cj7CwWADAyZPhOHgwFN27V5c4GRFRyZfvOUKl/htnepK6LTeRLgfR/2VkKDFv3km0br1ZVQRZWRlj69Ye6NatmsTpiIhKB62PGiu1/v1d3WYhRBILC4vFwIH7EBT0SNXXooUrfvqpJ9zdS+Z1/oiIdFG+CyGlUlmUOaSX/TpjnCxNEhFCYNu26xg37jASEtIAAHK5DLNne2PGjNYwNNT6ZPBERPQavLJobuTGUicgPXXp0hP4+f2quu3hYYft23uhWbMK0oUiIirF+PUSAEr7bj8qMRo3dsHIkV4AgCFD6uPq1ZEsgoiIihBHhAAgNU7qBKSn0tMVMDQ00DgYYdmyTujSpQonRBMRFQOOCAHAy2xnla41RLIYpF9CQmLQrNmP2LLlmka/hYUxiyAiomLCQggAoi6p23ZVpctBekEIgfXrL6FBg/W4fPkpxo8/gnv3SugZ2YmISjjuGgMARZrUCUhPREcnYfjw3xAQEKLqc3GxQnJyuoSpiIj0FwshAIgKVrfL1pIuB5VqgYH3MGTIAURGJqr6Ro3ywrJlPjA3N5IwGRGR/mIhBABG5uq2IU+mSIUrJSUD06cfw8qV51V99vbm2LSpG7p25VwgIiIpsRACgIcn1G2ritLloFLn3r0X6NVrF27ceKbq69y5MjZv7g4nJ0sJkxEREcBCKJORhbptVla6HFTq2NmZ4vnzzLOWm5jIsXTpOxg3rknpv3YfEVEJwaPGAEBkqNtm9tLloFKnbFlz+Pt3R716jrh06WOMH9+URRARkQ7hiBAARF/P/NfIApCxNqSC++23EDRu7KKx2+uddzwRHOwOuZy/W0REuob/M2dnwqt6U8EkJaVh1KiD6NZtJz766ADEfy7bwiKIiEg38X9nIQD8f1dF4iNJo1DJFBz8BA0bbsD69ZmnYThy5B4OHgyVOBUREeUHC6HUlwD+/+29Ygcpk1AJo1AosXjxGTRr9iNCQ58DAMzNjbBxY1e8/z7PUE5EVBJwjlByjLrNidKUTxERcRg0aD9OnfpX1efl5YwdO3qjalUeeUhEVFKwEEp6qm4bmkmXg0qMXbtuYtSoQ3j5MgUAIJMB06a1wty5bWFsLJc4HRERaYOFUEKEuq1IlS4HlQh///0I/frtVd12dbXGtm094e3tJl0oIiIqMM4RUmS72KVFeelyUInQrFkFDBpUFwDg61sL166NYhFERFSCcUToVZS6XbaGdDlIJymVAgYGmidA/O67LnjvvSro27cWT45IRFTCcUQoeyEkN5YuB+mcsLBYtGq1Cbt339Lot7Y2ga9vbRZBRESlAEeEjLJd+NLYWrocpDOEENi27TrGjTuMhIQ03LlzEM2bV4Crq43U0YiIqJBxROjpeXWbh8/rvdjYZPTrtxd+fr8iISENAFCmjJnqwqlERFS6cETIwlHdNjCSLgdJ7uTJcAwatB+PHsWr+oYMqY/VqzvDyspEwmRERFRUWAgpFeq2GU+Ep4/S0hSYPfsEliw5i6xLhNnammLDhvfRp08tacMREVGRYiGUlqBuG5pLl4MkERYWiz599uDyZfWJNdu2dcPWrT04J4iISA9wjlBqrLptYitZDJKGmZkhHj6MAwAYGRlgyZKOOH58MIsgIiI9wUIo4/+TYGVywIiX2NA3zs5W+PHHbqhe3R5//z0cn33WMsd5g4iIqPTirrGo4Mx/eZ0xvXDsWBgaNHBC2bLq3aDdulXDu+9WhpERrxNGRKRvOCKUhSfHK9VSUjIwceJRvPPONowceRAia1b0/7EIIiLSTyyEss4dlH3SNJUqN25EoUmTjVi5MvOcUXv33sHRo/ckTkVERLqAhVByTOa/9rWlzUGFTqkUWLXqbzRuvBE3bjwDAJiYyLF6dWd07lxZ4nRERKQL9HuOUPZzCGW/Cj2VeE+fJmDo0AMIDLyv6qtTxwE7dvRG7doOEiYjIiJdot+FUPbdYcnR0uWgQhUQEIJhwwIQE/NK1TdxYjMsXNgBpqb6/StPRESa9PtTIWu3GAC4tpUsBhWes2cfonv3narbTk6W2LKlBzp18pQwFRER6Sr9niOUnqRuC6V0OajQtGjhip49qwMAunevhhs3RrMIIiKiPOn3iFDiY3XbylW6HFRgQgjIsp36QCaTYePGrujWrRr8/Opp3EdERPRf+j0ipMw2QZqHz5c4ERFxaN9+Kw4eDNXoL1vWHEOG1GcRREREb6TfI0LPb6vbDg2ky0Fa2737FkaOPIiXL1Nw69YzXL8+Gk5OllLHIiKiEka/R4SMsl1tPiNFuhyUb/HxqRgy5Ff4+v6Cly8z3zNTU0M8ecIRPSIi0p5+jwilxqvbZWtIl4PyJSgoAgMG7MODBy9Vfb6+tbB27Xuws+O14oiISHv6XQhlP3w+61IbpHMyMpSYP/805s8/DYUi8xphVlbGWLOmCwYOrMu5QEREVGD6XQj9+7u6bWIjXQ7KU3j4S/TvvxdBQY9UfS1auOKnn3rC3d1OwmRERFQa6PccIbtq6raRlXQ5KE8GBjLcvp151m+5XIZ589ri1KkhLIKIiKhQ6HchlBqrbpuVkS4H5aliRRusW/c+PDzscObMR5g92xuGhvr9a0tERIVHvz9RsuYIGRgBhuavX5aKxV9//Yv4+FSNvn79auPWrTFo1qyCRKmIiKi00olCaM2aNXBzc4OpqSmaNm2KCxcu5Lnsxo0b0bp1a9jZ2cHOzg4dO3Z87fKvlfL/ESEze4ATbiWVlqbAtGnH4O3tj/Hjj+S4nxdLJSKioiB5IbRr1y5MmjQJc+bMweXLl1GvXj34+Pjg2bNnuS5/8uRJfPjhhzhx4gSCgoLg6uqKTp064fHjx7kunych1FecN7F9uydBbyUkJAbNm/+IxYvPQghg69Zr+P33+1LHIiIiPSATQggpAzRt2hSNGzfGd999BwBQKpVwdXXF+PHjMW3atDeur1AoYGdnh++++w6DBw9+4/Lx8fGwsbFBXPRjWG9xyex0bQv0PfE2T4MKQAiBDRuCMXFiIJKTMwAARkYGWLCgPSZPbgEDA47SERFRJtXnd1wcrK2tC227ku5vSEtLQ3BwMKZPn67qMzAwQMeOHREUFJSvbbx69Qrp6ekoUyb3yc6pqalITVXPOYmP//9JFFNeqheSm2qdnd5OdHQShg//DQEBIaq+atXKYseO3mjY0FnCZEREpE8k3TUWExMDhUIBR0dHjX5HR0dERkbmaxtTp05F+fLl0bFjx1zvX7RoEWxsbFQ/rq7/v8p8RpJ6oYSHBcpPBRMYeA91667TKIJGj26Ey5dHsggiIqJiJfkcobfx9ddfY+fOndi/fz9MTXMf1Zk+fTri4uJUPxEREZl3JD5RL+TavhjSEpB5VFjnztsRGZkIALC3N0dAQD98//17MDc3kjgdERHpG0l3jdnb20MulyMqKkqjPyoqCk5OTq9d95tvvsHXX3+NY8eOoW7dunkuZ2JiAhMTk5x3CIW6najlRGsqsFatKqJz58o4evQeOneujM2bu/Oq8UREJBlJR4SMjY3h5eWF48ePq/qUSiWOHz+O5s2b57nekiVL8NVXX+Ho0aNo1KhRwR485YW6XT7vx6LCJZPJsHlzd3z/fRccPtyfRRAREUlK8l1jkyZNwsaNG7FlyxbcuXMHo0ePRlJSEoYOHQoAGDx4sMZk6sWLF+OLL77Apk2b4ObmhsjISERGRiIxMVG7B07JdlZpU55VuihERibivfd24PjxMI1+JydLjB7dmBdLJSIiyUl+ljpfX19ER0dj9uzZiIyMRP369XH06FHVBOqHDx/CwEBdr61duxZpaWn44IMPNLYzZ84czJ07N/8PnJ6gbpuWfZunQLkICAjBsGEBiIl5hWvXInHt2iiULcuzdxMRkW6RvBACgHHjxmHcuHG53nfy5EmN2+Hh4YXzoKnx6raRReFsk5CUlIbJk3/H+vXBqj6lUiA8/CULISIi0jk6UQhJIj1Z3TaxkS5HKRIc/AQDBuxDSMhzVV+PHtWxcWNX2NuzCCIiIt2jv4WQItuFPQ15QsW3oVAo8c035zBr1glkZCgBAObmRli1qjOGDWvAuUBERKSz9LcQirmmbstzObye8uXRo3gMGrQfJ0+Gq/q8vJyxY0dvVK3KuVdERKTbJD9qTDKG2eYFyY2ly1HCJSen4+LFzPMwyWTA9OmtcO7cMBZBRERUIuhvIWScrRAyspIuRwlXpUpZrF79LlxdrXHihB8WLuwAY2O51LGIiIjyRX8LoQzOESqICxce49WrdI2+oUPr4/btsfD2dpMmFBERUQHpbyH06JS6zULojTIylJg37yRatPgRU6b8rnGfTCaDpSV3LxIRUcmjv4WQfS1120B/54znR1hYLNq02Yy5c09BoRBYu/YSTpx4IHUsIiKit6a/FUD2XWOUKyEEtm27jnHjDiMhIQ0AIJfLMHu2N1q3riRxOiIiorenv4XQy3uAKQBzR6mT6KTY2GSMHn0Iu3bdUvV5eNhh+/ZeaNasgoTJiIiICo/+FkIqQuoAOufUqXAMGrQfERHqy5AMGVIfq1d3hpUVz7lERESlh/4WQoZmAJKBV8+kTqJTTp0KR7t2WyD+Xx/a2Zli/fr30adPrdevSEREVALp72TprEtsOHpJm0PHtGpVEW3aZM7/adfODdevj2YRREREpZb+jgiJzGti8fIamuRyA2zb1hN79tzGp582g4EBrxNGRESll/6OCGUx1N+rokdHJ6F37904e/ahRr+rqw0mTWrOIoiIiEo9/R0RymKmn9fECgy8hyFDDiAyMhGXLz/FtWujYG3N0TEiItIvHBES+nXUWEpKBj799Cg6d96OyMhEAEBiYhpCQ59LnIyIiKj4cUQoI0nqBMXmxo0o9O+/Dzdvqo+U69y5MjZv7g4nJ0sJkxEREUmDhZBDA6kTFDmlUuDbb89j6tRjSE1VAABMTORYuvQdjBvXBDIZ5wIREZF+YiGkSJM6QZF6+jQBQ4ceQGDgfVVfnToO2LGjN2rXdpAwGRERkfQ4R6iUHz7/4kUyTp4MV92eOLEZLlwYwSKIiIgILIQAq4pSJyhStWo5YOnSd+DkZInAwIFYvtwHpqYcCCQiIgJYCAFyY6kTFKpr1yKRmpqh0TduXBPcvj0GnTp5SpSKiIhIN7EQMpBLnaBQKBRKLF58Bo0abcTMmX9q3CeTyWBnZyZRMiIiIt3FQsiivNQJ3lpERBw6dNiKadOOIyNDiWXLgnDmzMM3r0hERKTnOFmkhI8I7d59CyNHHsTLlykAAJkMmDatFZo0cZE4GRERke5jIWRWMo+eio9PxYQJR7BlyzVVn6urNbZt6wlvbzfpghEREZUgLISMS94ZlYOCIjBw4H6EhcWq+nx9a2Ht2vc4F4iIiEgL+l0IyQwAC2epU2jl5MlwdOy4FQpF5jXSrKyMsWZNFwwcWJdniCYiItKSfk+WFsoSN0eoZUtXeHllTvBu0cIV166NwqBB9VgEERERFYB+jwgZmkudQGtGRnJs394Lu3bdxNSprWBoqN+1LBER0dvQ70LIQLeffmxsMsaNO4JJk5qpRoEAoHLlMpg5s42EyYj0ixACGRkZUCgUUkchKtWMjIwglxfvnhrdrgSKmqXuHmJ+8mQ4Bg3aj0eP4hEc/ASXL4+EubmR1LGI9E5aWhqePn2KV69eSR2FqNSTyWSoUKECLC2L70Am/S6EbCtLnSCHtDQFZs8+gSVLzkJkzofGs2dJuHXrGRo31t3Cjag0UiqVePDgAeRyOcqXLw9jY2POxyMqIkIIREdH49GjR6hSpUqxjQzpdyEUGyp1Ag0hITHo338fLl9+qupr184NW7f2RIUK1hImI9JPaWlpUCqVcHV1hbl5yZtTSFTSlCtXDuHh4UhPT2chVCwqtpM6AYDMKnjDhmBMnBiI5OTMC6YaGRlgwYL2mDy5BQwM+A2USEoGBjwogag4SDHiqt+FkIH0V56Pjk7C8OG/ISAgRNVXrVpZ7NjRGw0blqxzHBEREZU0+l0IyaT/lhcREY/Dh/9R3R49uhG++aYTJ0YTEREVA+krASklREidAA0bOmP+/HawtzdHQEA/fP/9eyyCiIgkFBISAicnJyQkJEgdpdRp1qwZ9u7dK3UMDfpdCDk2LPaHvHs3BunpmucimTKlBW7dGoOuXasVex4iKp2GDBkCmUwGmUwGIyMjuLu74/PPP0dKSkqOZQ8ePAhvb29YWVnB3NwcjRs3hr+/f67b3bt3L9q2bQsbGxtYWlqibt26+PLLL/HixYsifkbFZ/r06Rg/fjysrKykjlJk1qxZAzc3N5iamqJp06a4cOHCa5dPT0/Hl19+CU9PT5iamqJevXo4evRojuUeP36MgQMHomzZsjAzM0OdOnVw6dIl1f2zZs3CtGnToFQqC/05FZR+F0LFOEdIqRRYtepv1K+/DvPnn9a4Ty43gIODRbFlISL90LlzZzx9+hRhYWFYsWIF1q9fjzlz5mgs8+2336J79+5o2bIlzp8/j+vXr6Nfv34YNWoUpkyZorHszJkz4evri8aNG+PIkSO4efMmli1bhmvXrmHbtm3F9rzS0tKKbNsPHz7EwYMHMWTIkLfaTlFmfFu7du3CpEmTMGfOHFy+fBn16tWDj48Pnj17luc6s2bNwvr16/Htt9/i9u3bGDVqFHr27IkrV66olomNjUXLli1hZGSEI0eO4Pbt21i2bBns7OxUy7z77rtISEjAkSNHivQ5akXombi4OAFAxM2HEMGri+UxnzyJFz4+2wQwVwBzhYHBPHH+/KNieWwiKrjk5GRx+/ZtkZycLHUUrfn5+Ynu3btr9PXq1Us0aNBAdfvhw4fCyMhITJo0Kcf6q1evFgDE33//LYQQ4vz58wKAWLlyZa6PFxsbm2eWiIgI0a9fP2FnZyfMzc2Fl5eXaru55fzkk0+Et7e36ra3t7cYO3as+OSTT0TZsmVF27ZtxYcffij69u2rsV5aWpooW7as2LJlixBCCIVCIRYuXCjc3NyEqampqFu3rtizZ0+eOYUQYunSpaJRo0YafTExMaJfv36ifPnywszMTNSuXVvs2LFDY5ncMgohxI0bN0Tnzp2FhYWFcHBwEAMHDhTR0dGq9Y4cOSJatmwpbGxsRJkyZcR7770n7t2799qMb6tJkyZi7NixqtsKhUKUL19eLFq0KM91nJ2dxXfffafR16tXLzFgwADV7alTp4pWrVq98fGHDh0qBg4cmOt9r/ubU31+x8W98TG0od+TpY2K/rwgBw7cxfDhvyEmRn1W2gkTmqBuXccif2wiKiI/NQKSIov3MS2cgIGX3rxcHm7evIlz586hUqVKqr5ffvkF6enpOUZ+AGDkyJGYMWMGfv75ZzRt2hTbt2+HpaUlxowZk+v2bW1tc+1PTEyEt7c3XFxcEBAQACcnJ1y+fFnrXSNbtmzB6NGjcfbsWQDAvXv30KdPHyQmJqrOQhwYGIhXr16hZ8+eAIBFixbhp59+wrp161ClShWcPn0aAwcORLly5eDt7Z3r4/z1119o1KiRRl9KSgq8vLwwdepUWFtb49ChQxg0aBA8PT3RpEmTPDO+fPkS7du3x/Dhw7FixQokJydj6tSp6Nu3L/78808AQFJSEiZNmoS6desiMTERs2fPRs+ePXH16tU8T9uwcOFCLFy48LWv1+3bt1GxYsUc/WlpaQgODsb06dNVfQYGBujYsSOCgoLy3F5qaipMTU01+szMzHDmzBnV7YCAAPj4+KBPnz44deoUXFxcMGbMGIwYMUJjvSZNmuDrr79+bf7ipN+FUBFeaywpKQ2TJ/+O9euDVX1OTpbYsqUHOnXyLLLHJaJikBQJJD6WOsUbHTx4EJaWlsjIyEBqaioMDAzw3Xffqe4PDQ2FjY0NnJ1znqrD2NgYHh4eCA3NPPHsP//8Aw8PDxgZaXcwx44dOxAdHY2LFy+iTJkyAIDKlbU/q3+VKlWwZMkS1W1PT09YWFhg//79GDRokOqxunXrBisrK6SmpmLhwoU4duwYmjdvDgDw8PDAmTNnsH79+jwLoX///TdHIeTi4qJRLI4fPx6BgYHYvXu3RiH034zz589HgwYNNIqWTZs2wdXVFaGhoahatSp69+6t8VibNm1CuXLlcPv2bdSuXTvXjKNGjULfvn1f+3qVL18+1/6YmBgoFAo4Omp+GXd0dMTdu3fz3J6Pjw+WL1+ONm3awNPTE8ePH8e+ffs0rr8XFhaGtWvXYtKkSZgxYwYuXryICRMmwNjYGH5+fhrZIiIioFQqdeIcXfpdCBXR4fPBwU/Qv/8+hIY+V/V1714NP/zQDfb2PDstUYln4VQiHrNdu3ZYu3YtkpKSsGLFChgaGub44M0vkXXNHy1dvXoVDRo0UBVBBeXl5aVx29DQEH379sX27dsxaNAgJCUl4cCBA9i5cyeAzBGjV69e4Z133tFYLy0tDQ0aNMjzcZKTk3OMfCgUCixcuBC7d+/G48ePkZaWhtTU1BxnG/9vxmvXruHEiRO5Xjfr/v37qFq1Kv755x/Mnj0b58+fR0xMjGqk7OHDh3kWQmXKlHnr11Nbq1atwogRI1C9enXIZDJ4enpi6NCh2LRpk2oZpVKJRo0aqQq/Bg0a4ObNm1i3bp1GIWRmZgalUonU1FSYmZkV6/PIjX4XQij8M1j++ecD+Pj8hIyMzF9mc3MjrFzpg+HDG/IaRUSlxVvsoipOFhYWqtGXTZs2oV69evjxxx8xbNgwAEDVqlURFxeHJ0+e5BhBSEtLw/3799GuXTvVsmfOnEF6erpWo0Jv+qAzMDDIUWSlp6fn+lz+a8CAAfD29sazZ8/wxx9/wMzMDJ07dwaQuUsOAA4dOgQXF83rNJqYmOSZx97eHrGxsRp9S5cuxapVq7By5UrUqVMHFhYW+PTTT3NMiP5vxsTERHTt2hWLFy/O8ThZo3Bdu3ZFpUqVsHHjRpQvXx5KpRK1a9d+7WTrt9k1Zm9vD7lcjqioKI3+qKgoODnlXWyXK1cOv/76K1JSUvD8+XOUL18e06ZNg4eHh8ZzqlmzpsZ6NWrUyHG4/IsXL2BhYaETRRCg70eNFcGIUMuWrqhZsxwAwMvLGVeujMSIEV4sgohIUgYGBpgxYwZmzZqF5ORkAEDv3r1hZGSEZcuW5Vh+3bp1SEpKwocffggA6N+/PxITE/H999/nuv2XL1/m2l+3bl1cvXo1z8Pry5Urh6dPn2r0Xb16NV/PqUWLFnB1dcWuXbuwfft29OnTR1Wk1axZEyYmJnj48CEqV66s8ePq6prnNhs0aIDbt29r9J09exbdu3fHwIEDUa9ePY1dhq/TsGFD3Lp1C25ubjkyWFhY4Pnz5wgJCcGsWbPQoUMH1KhRI0cRlptRo0bh6tWrr/3Ja9eYsbExvLy8cPz4cVWfUqnE8ePHVbsQX8fU1BQuLi7IyMjA3r170b17d9V9LVu2REhIiMbyoaGhGvPSgMz5aq8blSt2hTr1ugTQOGrs9o43r1AAN29GiZkzj4vU1Iwi2T4RFY/SdtRYenq6cHFxEUuXLlX1rVixQhgYGIgZM2aIO3fuiHv37olly5YJExMTMXnyZI31P//8cyGXy8Vnn30mzp07J8LDw8WxY8fEBx98kOfRZKmpqaJq1aqidevW4syZM+L+/fvil19+EefOnRNCCHH06FEhk8nEli1bRGhoqJg9e7awtrbOcdTYJ598kuv2Z86cKWrWrCkMDQ3FX3/9leO+smXLCn9/f3Hv3j0RHBwsVq9eLfz9/fN83QICAoSDg4PIyFD//z1x4kTh6uoqzp49K27fvi2GDx8urK2tNV7f3DI+fvxYlCtXTnzwwQfiwoUL4t69e+Lo0aNiyJAhIiMjQygUClG2bFkxcOBA8c8//4jjx4+Lxo0bCwBi//79eWZ8Wzt37hQmJibC399f3L59W3z88cfC1tZWREZGqpYZNGiQmDZtmur233//Lfbu3Svu378vTp8+Ldq3by/c3d01jha8cOGCMDQ0FAsWLBD//POP2L59uzA3Nxc//fSTxuN7e3uLL7/8MtdsUhw1pt+F0J2db7mtFDF8+AFx82ZUIaUjIl1S2gohIYRYtGiRKFeunEhMTFT1HThwQLRu3VpYWFgIU1NT4eXlJTZt2pTrdnft2iXatGkjrKyshIWFhahbt6748ssvX3v4fHh4uOjdu7ewtrYW5ubmolGjRuL8+fOq+2fPni0cHR2FjY2NmDhxohg3bly+C6Hbt28LAKJSpUpCqVRq3KdUKsXKlStFtWrVhJGRkShXrpzw8fERp06dyjNrenq6KF++vDh69Kiq7/nz56J79+7C0tJSODg4iFmzZonBgwe/sRASQojQ0FDRs2dPYWtrK8zMzET16tXFp59+qsr6xx9/iBo1aggTExNRt25dcfLkySIvhIQQ4ttvvxUVK1YUxsbGokmTJqrTGWR/Pn5+fqrbJ0+eVOUsW7asGDRokHj8+HGO7f7222+idu3awsTERFSvXl1s2LBB4/5Hjx4JIyMjERERkWsuKQohmRAFnAFXQsXHx8PGxgZx8wHrD3YB1V4/8z4vQUERGDhwP8LCYlG3riMuXBgOExM9n3JFVMqkpKTgwYMHcHd3zzGBlkqvNWvWICAgAIGBgVJHKXWmTp2K2NhYbNiwIdf7X/c3p/r8jouDtbV1oWXiHCEtZWQoMW/eSbRuvRlhYZn7ch88iMX161FvWJOIiEqCkSNHok2bNrzWWBFwcHDAV199JXUMDXo+hKHdBOawsFgMHLgPQUGPVH0tWrjip596wt3d7jVrEhFRSWFoaIiZM2dKHaNUmjx5stQRctDvQiifI0JCCGzbdh3jxh1GQkLmIY1yuQyzZ3tjxozWMDTU74E1IiKikkq/C6F8jAjFxiZj9OhD2LXrlqrPw8MO27f3QrNmFYoyHBERERUx/S6E8jEidOdODPbsUZ9TYsiQ+li9ujOsrPI+IRcRlS56dkwJkWSk+FvT7306+SiEWrRwxcyZrWFra4rduz/A5s3dWQQR6Ymsk/O9evXqDUsSUWHIOqO2XC4vtsfU8xGhnLvGHjyIRcWKNpDL1UXSF1+0wciRXnBxKbzD9YhI98nlctja2uLZs2cAAHNzc54lnqiIKJVKREdHw9zcHIaGxVee6HkhpC52hBDYsCEYEycGYs4cb0yd2kp1n5GRnEUQkZ7Kuv5SVjFEREXHwMAAFStWLNYvHPpdCP1/snR0dBKGD/8NAQGZ10iZNesEOnXyRIMGzlKGIyIdIJPJ4OzsDAcHh1wvBkpEhcfY2BgGBsU7a0cnCqE1a9Zg6dKliIyMRL169fDtt9+iSZMmeS6/Z88efPHFFwgPD0eVKlWwePFidOnSRfsHlhkgMPAehgw5gMjIRFX38OENUK2afUGeChGVUnK5vFjnLRBR8ZB8svSuXbswadIkzJkzB5cvX0a9evXg4+OT5zD0uXPn8OGHH2LYsGG4cuUKevTogR49euDmzZtaPW5KuhyfzruPzp23q4oge3tzBAT0w9q178Pc3OitnxsRERHpNsmvNda0aVM0btwY3333HYDMyVKurq4YP348pk2blmN5X19fJCUl4eDBg6q+Zs2aoX79+li3bt0bHy/rWiU1HIbhzjNXVX/nzpWxeXN3ODlZFsKzIiIiosJUKq81lpaWhuDgYHTs2FHVZ2BggI4dOyIoKCjXdYKCgjSWBwAfH588l8/LnWflAAAmJnKsXt0Zhw/3ZxFERESkZySdIxQTEwOFQgFHR0eNfkdHR9y9ezfXdSIjI3NdPjIyMtflU1NTkZqaqrodFxeXdQ9qVrPFj/4foGbNcry4HhERkQ6Lj48HUPgnXdSJydJFadGiRZg3b14u96zA7RCgefOcu9+IiIhINz1//hw2NjaFtj1JCyF7e3vI5XJERUVp9EdFRanO3fFfTk5OWi0/ffp0TJo0SXX75cuXqFSpEh4+fFioLyRpLz4+Hq6uroiIiCjU/b1UMHw/dAffC93B90J3xMXFoWLFiihTpkyhblfSQsjY2BheXl44fvw4evToASBzsvTx48cxbty4XNdp3rw5jh8/jk8//VTV98cff6B58+a5Lm9iYgITk5yXxLCxseEvtY6wtrbme6FD+H7oDr4XuoPvhe4o7PMMSb5rbNKkSfDz80OjRo3QpEkTrFy5EklJSRg6dCgAYPDgwXBxccGiRYsAAJ988gm8vb2xbNkyvPfee9i5cycuXbqEDRs2SPk0iIiIqASSvBDy9fVFdHQ0Zs+ejcjISNSvXx9Hjx5VTYh++PChRvXXokUL7NixA7NmzcKMGTNQpUoV/Prrr6hdu7ZUT4GIiIhKKMkLIQAYN25cnrvCTp48maOvT58+6NOnT4Eey8TEBHPmzMl1dxkVL74XuoXvh+7ge6E7+F7ojqJ6LyQ/oSIRERGRVCS/xAYRERGRVFgIERERkd5iIURERER6i4UQERER6a1SWQitWbMGbm5uMDU1RdOmTXHhwoXXLr9nzx5Ur14dpqamqFOnDg4fPlxMSUs/bd6LjRs3onXr1rCzs4OdnR06duz4xveOtKPt30aWnTt3QiaTqU58Sm9P2/fi5cuXGDt2LJydnWFiYoKqVavy/6pCou17sXLlSlSrVg1mZmZwdXXFxIkTkZKSUkxpS6/Tp0+ja9euKF++PGQyGX799dc3rnPy5Ek0bNgQJiYmqFy5Mvz9/bV/YFHK7Ny5UxgbG4tNmzaJW7duiREjRghbW1sRFRWV6/Jnz54VcrlcLFmyRNy+fVvMmjVLGBkZiRs3bhRz8tJH2/eif//+Ys2aNeLKlSvizp07YsiQIcLGxkY8evSomJOXTtq+H1kePHggXFxcROvWrUX37t2LJ2wpp+17kZqaKho1aiS6dOkizpw5Ix48eCBOnjwprl69WszJSx9t34vt27cLExMTsX37dvHgwQMRGBgonJ2dxcSJE4s5eelz+PBhMXPmTLFv3z4BQOzfv/+1y4eFhQlzc3MxadIkcfv2bfHtt98KuVwujh49qtXjlrpCqEmTJmLs2LGq2wqFQpQvX14sWrQo1+X79u0r3nvvPY2+pk2bipEjRxZpTn2g7XvxXxkZGcLKykps2bKlqCLqlYK8HxkZGaJFixbihx9+EH5+fiyECom278XatWuFh4eHSEtLK66IekPb92Ls2LGiffv2Gn2TJk0SLVu2LNKc+iY/hdDnn38uatWqpdHn6+srfHx8tHqsUrVrLC0tDcHBwejYsaOqz8DAAB07dkRQUFCu6wQFBWksDwA+Pj55Lk/5U5D34r9evXqF9PT0Qr/Anj4q6Pvx5ZdfwsHBAcOGDSuOmHqhIO9FQEAAmjdvjrFjx8LR0RG1a9fGwoULoVAoiit2qVSQ96JFixYIDg5W7T4LCwvD4cOH0aVLl2LJTGqF9fmtE2eWLiwxMTFQKBSqy3NkcXR0xN27d3NdJzIyMtflIyMjiyynPijIe/FfU6dORfny5XP8opP2CvJ+nDlzBj/++COuXr1aDAn1R0Hei7CwMPz5558YMGAADh8+jHv37mHMmDFIT0/HnDlziiN2qVSQ96J///6IiYlBq1atIIRARkYGRo0ahRkzZhRHZMomr8/v+Ph4JCcnw8zMLF/bKVUjQlR6fP3119i5cyf2798PU1NTqePonYSEBAwaNAgbN26Evb291HH0nlKphIODAzZs2AAvLy/4+vpi5syZWLdundTR9M7JkyexcOFCfP/997h8+TL27duHQ4cO4auvvpI6GhVQqRoRsre3h1wuR1RUlEZ/VFQUnJyccl3HyclJq+UpfwryXmT55ptv8PXXX+PYsWOoW7duUcbUG9q+H/fv30d4eDi6du2q6lMqlQAAQ0NDhISEwNPTs2hDl1IF+dtwdnaGkZER5HK5qq9GjRqIjIxEWloajI2NizRzaVWQ9+KLL77AoEGDMHz4cABAnTp1kJSUhI8//hgzZ87UuEg4Fa28Pr+tra3zPRoElLIRIWNjY3h5eeH48eOqPqVSiePHj6N58+a5rtO8eXON5QHgjz/+yHN5yp+CvBcAsGTJEnz11Vc4evQoGjVqVBxR9YK270f16tVx48YNXL16VfXTrVs3tGvXDlevXoWrq2txxi9VCvK30bJlS9y7d09VjAJAaGgonJ2dWQS9hYK8F69evcpR7GQVqIKX7ixWhfb5rd08bt23c+dOYWJiIvz9/cXt27fFxx9/LGxtbUVkZKQQQohBgwaJadOmqZY/e/asMDQ0FN988424c+eOmDNnDg+fLyTavhdff/21MDY2Fr/88ot4+vSp6ichIUGqp1CqaPt+/BePGis82r4XDx8+FFZWVmLcuHEiJCREHDx4UDg4OIj58+dL9RRKDW3fizlz5ggrKyvx888/i7CwMPH7778LT09P0bdvX6meQqmRkJAgrly5Iq5cuSIAiOXLl4srV66If//9VwghxLRp08SgQYNUy2cdPv/ZZ5+JO3fuiDVr1vDw+SzffvutqFixojA2NhZNmjQRf//9t+o+b29v4efnp7H87t27RdWqVYWxsbGoVauWOHToUDEnLr20eS8qVaokAOT4mTNnTvEHL6W0/dvIjoVQ4dL2vTh37pxo2rSpMDExER4eHmLBggUiIyOjmFOXTtq8F+np6WLu3LnC09NTmJqaCldXVzFmzBgRGxtb/MFLmRMnTuT6GZD1+vv5+Qlvb+8c69SvX18YGxsLDw8PsXnzZq0fVyYEx/KIiIhIP5WqOUJERERE2mAhRERERHqLhRARERHpLRZCREREpLdYCBEREZHeYiFEREREeouFEBEREektFkJEpMHf3x+2trZSxygwmUyGX3/99bXLDBkyBD169CiWPESk21gIEZVCQ4YMgUwmy/Fz7949qaPB399flcfAwAAVKlTA0KFD8ezZs0LZ/tOnT/Huu+8CAMLDwyGTyXD16lWNZVatWgV/f/9Ceby8zJ07V/U85XI5XF1d8fHHH+PFixdabYdFG1HRKlVXnycitc6dO2Pz5s0afeXKlZMojSZra2uEhIRAqVTi2rVrGDp0KJ48eYLAwMC33nZeVw3PzsbG5q0fJz9q1aqFY8eOQaFQ4M6dO/joo48QFxeHXbt2FcvjE9GbcUSIqJQyMTGBk5OTxo9cLsfy5ctRp04dWFhYwNXVFWPGjEFiYmKe27l27RratWsHKysrWFtbw8vLC5cuXVLdf+bMGbRu3RpmZmZwdXXFhAkTkJSU9NpsMpkMTk5OKF++PN59911MmDABx44dQ3JyMpRKJb788ktUqFABJiYmqF+/Po4ePapaNy0tDePGjYOzszNMTU1RqVIlLFq0SGPbWbvG3N3dAQANGjSATCZD27ZtAWiOsmzYsAHly5fXuLI7AHTv3h0fffSR6vaBAwfQsGFDmJqawsPDA/PmzUNGRsZrn6ehoSGcnJzg4uKCjh07ok+fPvjjjz9U9ysUCgwbNgzu7u4wMzNDtWrVsGrVKtX9c+fOxZYtW3DgwAHV6NLJkycBABEREejbty9sbW1RpkwZdO/eHeHh4a/NQ0Q5sRAi0jMGBgZYvXo1bt26hS1btuDPP//E559/nufyAwYMQIUKFXDx4kUEBwdj2rRpMDIyAgDcv38fnTt3Ru/evXH9+nXs2rULZ86cwbhx47TKZGZmBqVSiYyMDKxatQrLli3DN998g+vXr8PHxwfdunXDP//8AwBYvXo1AgICsHv3boSEhGD79u1wc3PLdbsXLlwAABw7dgxPnz7Fvn37cizTp08fPH/+HCdOnFD1vXjxAkePHsWAAQMAAH/99RcGDx6MTz75BLdv38b69evh7++PBQsW5Ps5hoeHIzAwEMbGxqo+pVKJChUqYM+ePbh9+zZmz56NGTNmYPfu3QCAKVOmoG/fvujcuTOePn2Kp0+fokWLFkhPT4ePjw+srKzw119/4ezZs7C0tETnzp2RlpaW70xEBJTKq88T6Ts/Pz8hl8uFhYWF6ueDDz7Iddk9e/aIsmXLqm5v3rxZ2NjYqG5bWVkJf3//XNcdNmyY+PjjjzX6/vrrL2FgYCCSk5NzXee/2w8NDRVVq1YVjRo1EkIIUb58ebFgwQKNdRo3bizGjBkjhBBi/Pjxon379kKpVOa6fQBi//79QgghHjx4IACIK1euaCzj5+cnunfvrrrdvXt38dFHH6lur1+/XpQvX14oFAohhBAdOnQQCxcu1NjGtm3bhLOzc64ZhBBizpw5wsDAQFhYWAhTU1PVlbSXL1+e5zpCCDF27FjRu3fvPLNmPXa1atU0XoPU1FRhZmYmAgMDX7t9ItLEOUJEpVS7du2wdu1a1W0LCwsAmaMjixYtwt27dxEfH4+MjAykpKTg1atXMDc3z7GdSZMmYfjw4di2bZtq946npyeAzN1m169fx/bt21XLCyGgVCrx4MED1KhRI9dscXFxsLS0hFKpREpKClq1aoUffvgB8fHxePLkCVq2bKmxfMuWLXHt2jUAmbu13nnnHVSrVg2dO3fG+++/j06dOr3VazVgwACMGDEC33//PUxMTLB9+3b069cPBgYGqud59uxZjREghULx2tcNAKpVq4aAgACkpKTgp59+wtWrVzF+/HiNZdasWYNNmzbh4cOHSE5ORlpaGurXr//avNeuXcO9e/dgZWWl0Z+SkoL79+8X4BUg0l8shIhKKQsLC1SuXFmjLzw8HO+//z5Gjx6NBQsWoEyZMjhz5gyGDRuGtLS0XD/Q586di/79++PQoUM4cuQI5syZg507d6Jnz55ITEzEyJEjMWHChBzrVaxYMc9sVlZWuHz5MgwMDODs7AwzMzMAQHx8/BufV8OGDfHgwQMcOXIEx44dQ9++fdGxY0f88ssvb1w3L127doUQAocOHULjxo3x119/YcWKFar7ExMTMW/ePPTq1SvHuqampnlu19jYWPUefP3113jvvfcwb948fPXVVwCAnTt3YsqUKVi2bBmaN28OKysrLF26FOfPn39t3sTERHh5eWkUoFl0ZUI8UUnBQohIjwQHB0OpVGLZsmWq0Y6s+SivU7VqVVStWhUTJ07Ehx9+iM2bN6Nnz55o2LAhbt++naPgehMDA4Nc17G2tkb58uVx9uxZeHt7q/rPnj2LJk2aaCzn6+sLX19ffPDBB+jcuTNevHiBMmXKaGwvaz6OQqF4bR5TU1P06tUL27dvx71791CtWjU0bNhQdX/Dhg0REhKi9fP8r1mzZqF9+/YYPXq06nm2aNECY8aMUS3z3xEdY2PjHPkbNmyIXbt2wcHBAdbW1m+ViUjfcbI0kR6pXLky0tPT8e233yIsLAzbtm3DunXr8lw+OTkZ48aNw8mTJ/Hvv//i7NmzuHjxomqX19SpU3Hu3DmMGzcOV69exT///IMDBw5oPVk6u88++wyLFy/Grl27EBISgmnTpuHq1av45JNPAADLly/Hzz//jLt37yI0NBR79uyBk5NTrieBdHBwgJmZGY4ePYqoqCjExcXl+bgDBgzAoUOHsGnTJtUk6SyzZ8/G1q1bMW/ePNy6dQt37tzBzp07MWvWLK2eW/PmzVG3bl0sXLgQAFClShVcunQJgYGBCA0NxRdffIGLFy9qrOPm5obr168jJCQEMTExSE9Px4ABA2Bvb4/u3bvjr7/+woMHD3Dy5ElMmDABjx490ioTkd6TepISERW+3CbYZlm+fLlwdnYWZmZmwsfHR2zdulUAELGxsUIIzcnMqampol+/fsLV1VUYGxuL8uXLi3HjxmlMhL5w4YJ45513hKWlpbCwsBB169bNMdk5u/9Olv4vhUIh5s6dK1xcXISRkZGoV6+eOHLkiOr+DRs2iPr16wsLCwthbW0tOnToIC5fvqy6H9kmSwshxMaNG4Wrq6swMDAQ3t7eeb4+CoVCODs7CwDi/v37OXIdPXpUtGjRQpiZmQlra2vRpEkTsWHDhjyfx5w5c0S9evVy9P/888/CxMREPHz4UKSkpIghQ4YIGxsbYWtrK0aPHi2mTZumsd6zZ89Ury8AceLECSGEEE+fPhWDBw8W9vb2wsTERHh4eIgRI0aIuLi4PDMRUU4yIYSQthQjIiIikgZ3jREREZHeYiFEREREeouFEBEREektFkJERESkt1gIERERkd5iIURERER6i4UQERER6S0WQkRERKS3WAgRERGR3mIhRERERHqLhRARERHpLRZCREREpLf+B5RCjYBLV2nDAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "import joblib\n",
    "\n",
    "df = pd.read_parquet('dataset.parquet', engine='pyarrow')\n",
    "\n",
    "X = df[['inst', 'bi', 'time']]\n",
    "y = df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "l2_reg = 0.05\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(3,)))\n",
    "model.add(Dense(256, activation='relu', kernel_regularizer=l2(l2_reg)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu', kernel_regularizer=l2(l2_reg)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu', kernel_regularizer=l2(l2_reg)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32, activation='relu', kernel_regularizer=l2(l2_reg)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(16, activation='relu', kernel_regularizer=l2(l2_reg)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "optimizer = RMSprop(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=1024, validation_data=(X_valid_scaled, y_valid), callbacks=[early_stopping])\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(f'Test Accuracy: {accuracy:.4f}')\n",
    "\n",
    "model.save('nn_model.keras')\n",
    "joblib.dump(scaler, 'scaler.joblib')\n",
    "\n",
    "y_pred_prob = model.predict(X_test_scaled).ravel()\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a6c425",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c4ffa7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 24ms/step - accuracy: 0.6351 - loss: 9.7861 - val_accuracy: 0.5011 - val_loss: 1.3865\n",
      "Epoch 2/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.9008 - loss: 0.7145 - val_accuracy: 0.5011 - val_loss: 0.9340\n",
      "Epoch 3/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.9166 - loss: 0.3226 - val_accuracy: 0.5011 - val_loss: 0.9057\n",
      "Epoch 4/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.9180 - loss: 0.2838 - val_accuracy: 0.6404 - val_loss: 0.5595\n",
      "Epoch 5/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.9156 - loss: 0.2828 - val_accuracy: 0.7980 - val_loss: 0.4023\n",
      "Epoch 6/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.9204 - loss: 0.2670 - val_accuracy: 0.7542 - val_loss: 0.5450\n",
      "Epoch 7/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.9174 - loss: 0.2721 - val_accuracy: 0.7310 - val_loss: 0.4978\n",
      "Epoch 8/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.9204 - loss: 0.2610 - val_accuracy: 0.9275 - val_loss: 0.2339\n",
      "Epoch 9/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.9194 - loss: 0.2637 - val_accuracy: 0.7431 - val_loss: 0.4969\n",
      "Epoch 10/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.9184 - loss: 0.2619 - val_accuracy: 0.9001 - val_loss: 0.2734\n",
      "Epoch 11/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.9191 - loss: 0.2630 - val_accuracy: 0.6174 - val_loss: 0.8292\n",
      "Epoch 12/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.9184 - loss: 0.2686 - val_accuracy: 0.9370 - val_loss: 0.2445\n",
      "Epoch 13/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.9217 - loss: 0.2515 - val_accuracy: 0.9186 - val_loss: 0.2713\n",
      "Epoch 14/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.9243 - loss: 0.2471 - val_accuracy: 0.9285 - val_loss: 0.2338\n",
      "Epoch 15/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.9208 - loss: 0.2587 - val_accuracy: 0.7959 - val_loss: 0.4562\n",
      "Epoch 16/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.9118 - loss: 0.2830 - val_accuracy: 0.7883 - val_loss: 0.4396\n",
      "Epoch 17/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.9202 - loss: 0.2571 - val_accuracy: 0.8231 - val_loss: 0.3949\n",
      "Epoch 18/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.9215 - loss: 0.2518 - val_accuracy: 0.7131 - val_loss: 0.7153\n",
      "Epoch 19/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.9231 - loss: 0.2514 - val_accuracy: 0.9416 - val_loss: 0.2510\n",
      "Epoch 20/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.9210 - loss: 0.2540 - val_accuracy: 0.6712 - val_loss: 0.5740\n",
      "Epoch 21/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.9234 - loss: 0.2462 - val_accuracy: 0.6015 - val_loss: 0.8335\n",
      "Epoch 22/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.9219 - loss: 0.2517 - val_accuracy: 0.5898 - val_loss: 0.9314\n",
      "Epoch 23/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.9206 - loss: 0.2562 - val_accuracy: 0.6895 - val_loss: 0.7118\n",
      "Epoch 24/100\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.9227 - loss: 0.2500 - val_accuracy: 0.7176 - val_loss: 1.2775\n",
      "\u001b[1m1954/1954\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9306 - loss: 0.2329\n",
      "Test Accuracy: 0.9308\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['scaler.joblib']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, LeakyReLU\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from keras.optimizers import Adam\n",
    "import joblib\n",
    "\n",
    "df = pd.read_parquet('dataset.parquet', engine='pyarrow')\n",
    "\n",
    "X = df[['inst', 'bi', 'time']]\n",
    "y = df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "l2_reg = 0.05\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(3,)))\n",
    "\n",
    "model.add(Dense(256, activation='tanh', kernel_regularizer=l2(l2_reg)))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "model.add(Dense(128, activation='tanh', kernel_regularizer=l2(l2_reg)))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(64, activation='relu', kernel_regularizer=l2(l2_reg)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(32, activation='tanh', kernel_regularizer=l2(l2_reg)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(16, activation='relu', kernel_regularizer=l2(l2_reg)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "##reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)\n",
    "\n",
    "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=1024, validation_data=(X_valid_scaled, y_valid), callbacks=[early_stopping])\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "\n",
    "print(f'Test Accuracy: {accuracy:.4f}')\n",
    "\n",
    "model.save('nn_model.keras')\n",
    "\n",
    "joblib.dump(scaler, 'scaler.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4870eed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
